{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data= pd.read_excel('TOT_imputed_data.xlsx')\n",
    "data.drop('Label1-Mortality outcome',\n",
    "  axis='columns', inplace=True)\n",
    "label='Label2-SARS-CoV-2 nucleic acids'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import load_model\n",
    "#from matplotlib import pyplot\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define dataset\n",
    "features = np.array([f for f in data.columns if f not in [label]])\n",
    "X=data[features]\n",
    "X.to_numpy()\n",
    "y=data[label].map({'Positive': 0, 'Negative':1})\n",
    "y.to_numpy()\n",
    "\n",
    "# split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "\n",
    "# scale data\n",
    "t = MinMaxScaler()\n",
    "t.fit(X_train)\n",
    "X_train = t.transform(X_train)\n",
    "X_test = t.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 230)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 184)               42504     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 184)               736       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 184)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 115)               21275     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 115)               460       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 115)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 69)                8004      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 115)               8050      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 115)               460       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 115)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 184)               21344     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 184)               736       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 184)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 230)               42550     \n",
      "=================================================================\n",
      "Total params: 146,119\n",
      "Trainable params: 144,923\n",
      "Non-trainable params: 1,196\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "64/64 - 1s - loss: 0.1071 - val_loss: 0.0327\n",
      "Epoch 2/100\n",
      "64/64 - 0s - loss: 0.0142 - val_loss: 0.0255\n",
      "Epoch 3/100\n",
      "64/64 - 0s - loss: 0.0099 - val_loss: 0.0217\n",
      "Epoch 4/100\n",
      "64/64 - 0s - loss: 0.0089 - val_loss: 0.0188\n",
      "Epoch 5/100\n",
      "64/64 - 0s - loss: 0.0078 - val_loss: 0.0176\n",
      "Epoch 6/100\n",
      "64/64 - 0s - loss: 0.0076 - val_loss: 0.0167\n",
      "Epoch 7/100\n",
      "64/64 - 0s - loss: 0.0070 - val_loss: 0.0164\n",
      "Epoch 8/100\n",
      "64/64 - 0s - loss: 0.0070 - val_loss: 0.0160\n",
      "Epoch 9/100\n",
      "64/64 - 0s - loss: 0.0068 - val_loss: 0.0161\n",
      "Epoch 10/100\n",
      "64/64 - 0s - loss: 0.0063 - val_loss: 0.0157\n",
      "Epoch 11/100\n",
      "64/64 - 0s - loss: 0.0062 - val_loss: 0.0157\n",
      "Epoch 12/100\n",
      "64/64 - 0s - loss: 0.0061 - val_loss: 0.0156\n",
      "Epoch 13/100\n",
      "64/64 - 0s - loss: 0.0060 - val_loss: 0.0155\n",
      "Epoch 14/100\n",
      "64/64 - 0s - loss: 0.0058 - val_loss: 0.0154\n",
      "Epoch 15/100\n",
      "64/64 - 0s - loss: 0.0055 - val_loss: 0.0150\n",
      "Epoch 16/100\n",
      "64/64 - 0s - loss: 0.0055 - val_loss: 0.0152\n",
      "Epoch 17/100\n",
      "64/64 - 0s - loss: 0.0054 - val_loss: 0.0151\n",
      "Epoch 18/100\n",
      "64/64 - 0s - loss: 0.0053 - val_loss: 0.0151\n",
      "Epoch 19/100\n",
      "64/64 - 0s - loss: 0.0053 - val_loss: 0.0148\n",
      "Epoch 20/100\n",
      "64/64 - 0s - loss: 0.0052 - val_loss: 0.0147\n",
      "Epoch 21/100\n",
      "64/64 - 0s - loss: 0.0050 - val_loss: 0.0146\n",
      "Epoch 22/100\n",
      "64/64 - 0s - loss: 0.0048 - val_loss: 0.0144\n",
      "Epoch 23/100\n",
      "64/64 - 0s - loss: 0.0049 - val_loss: 0.0146\n",
      "Epoch 24/100\n",
      "64/64 - 0s - loss: 0.0047 - val_loss: 0.0144\n",
      "Epoch 25/100\n",
      "64/64 - 0s - loss: 0.0053 - val_loss: 0.0156\n",
      "Epoch 26/100\n",
      "64/64 - 0s - loss: 0.0048 - val_loss: 0.0144\n",
      "Epoch 27/100\n",
      "64/64 - 0s - loss: 0.0047 - val_loss: 0.0143\n",
      "Epoch 28/100\n",
      "64/64 - 0s - loss: 0.0045 - val_loss: 0.0142\n",
      "Epoch 29/100\n",
      "64/64 - 0s - loss: 0.0043 - val_loss: 0.0140\n",
      "Epoch 30/100\n",
      "64/64 - 0s - loss: 0.0043 - val_loss: 0.0141\n",
      "Epoch 31/100\n",
      "64/64 - 0s - loss: 0.0042 - val_loss: 0.0139\n",
      "Epoch 32/100\n",
      "64/64 - 0s - loss: 0.0043 - val_loss: 0.0140\n",
      "Epoch 33/100\n",
      "64/64 - 0s - loss: 0.0043 - val_loss: 0.0139\n",
      "Epoch 34/100\n",
      "64/64 - 0s - loss: 0.0042 - val_loss: 0.0139\n",
      "Epoch 35/100\n",
      "64/64 - 0s - loss: 0.0041 - val_loss: 0.0139\n",
      "Epoch 36/100\n",
      "64/64 - 0s - loss: 0.0040 - val_loss: 0.0138\n",
      "Epoch 37/100\n",
      "64/64 - 0s - loss: 0.0038 - val_loss: 0.0135\n",
      "Epoch 38/100\n",
      "64/64 - 0s - loss: 0.0039 - val_loss: 0.0138\n",
      "Epoch 39/100\n",
      "64/64 - 0s - loss: 0.0038 - val_loss: 0.0139\n",
      "Epoch 40/100\n",
      "64/64 - 0s - loss: 0.0039 - val_loss: 0.0136\n",
      "Epoch 41/100\n",
      "64/64 - 0s - loss: 0.0038 - val_loss: 0.0136\n",
      "Epoch 42/100\n",
      "64/64 - 0s - loss: 0.0038 - val_loss: 0.0137\n",
      "Epoch 43/100\n",
      "64/64 - 0s - loss: 0.0037 - val_loss: 0.0134\n",
      "Epoch 44/100\n",
      "64/64 - 0s - loss: 0.0036 - val_loss: 0.0134\n",
      "Epoch 45/100\n",
      "64/64 - 0s - loss: 0.0036 - val_loss: 0.0134\n",
      "Epoch 46/100\n",
      "64/64 - 0s - loss: 0.0035 - val_loss: 0.0133\n",
      "Epoch 47/100\n",
      "64/64 - 0s - loss: 0.0035 - val_loss: 0.0133\n",
      "Epoch 48/100\n",
      "64/64 - 0s - loss: 0.0036 - val_loss: 0.0134\n",
      "Epoch 49/100\n",
      "64/64 - 0s - loss: 0.0035 - val_loss: 0.0135\n",
      "Epoch 50/100\n",
      "64/64 - 0s - loss: 0.0036 - val_loss: 0.0134\n",
      "Epoch 51/100\n",
      "64/64 - 0s - loss: 0.0033 - val_loss: 0.0132\n",
      "Epoch 52/100\n",
      "64/64 - 0s - loss: 0.0034 - val_loss: 0.0130\n",
      "Epoch 53/100\n",
      "64/64 - 0s - loss: 0.0032 - val_loss: 0.0131\n",
      "Epoch 54/100\n",
      "64/64 - 0s - loss: 0.0033 - val_loss: 0.0134\n",
      "Epoch 55/100\n",
      "64/64 - 0s - loss: 0.0033 - val_loss: 0.0132\n",
      "Epoch 56/100\n",
      "64/64 - 0s - loss: 0.0032 - val_loss: 0.0130\n",
      "Epoch 57/100\n",
      "64/64 - 0s - loss: 0.0033 - val_loss: 0.0132\n",
      "Epoch 58/100\n",
      "64/64 - 0s - loss: 0.0033 - val_loss: 0.0132\n",
      "Epoch 59/100\n",
      "64/64 - 0s - loss: 0.0031 - val_loss: 0.0130\n",
      "Epoch 60/100\n",
      "64/64 - 0s - loss: 0.0033 - val_loss: 0.0132\n",
      "Epoch 61/100\n",
      "64/64 - 0s - loss: 0.0032 - val_loss: 0.0128\n",
      "Epoch 62/100\n",
      "64/64 - 0s - loss: 0.0031 - val_loss: 0.0129\n",
      "Epoch 63/100\n",
      "64/64 - 0s - loss: 0.0031 - val_loss: 0.0128\n",
      "Epoch 64/100\n",
      "64/64 - 0s - loss: 0.0031 - val_loss: 0.0128\n",
      "Epoch 65/100\n",
      "64/64 - 0s - loss: 0.0030 - val_loss: 0.0127\n",
      "Epoch 66/100\n",
      "64/64 - 0s - loss: 0.0031 - val_loss: 0.0127\n",
      "Epoch 67/100\n",
      "64/64 - 0s - loss: 0.0030 - val_loss: 0.0129\n",
      "Epoch 68/100\n",
      "64/64 - 0s - loss: 0.0030 - val_loss: 0.0130\n",
      "Epoch 69/100\n",
      "64/64 - 0s - loss: 0.0031 - val_loss: 0.0128\n",
      "Epoch 70/100\n",
      "64/64 - 0s - loss: 0.0030 - val_loss: 0.0127\n",
      "Epoch 71/100\n",
      "64/64 - 0s - loss: 0.0029 - val_loss: 0.0126\n",
      "Epoch 72/100\n",
      "64/64 - 0s - loss: 0.0030 - val_loss: 0.0126\n",
      "Epoch 73/100\n",
      "64/64 - 0s - loss: 0.0029 - val_loss: 0.0124\n",
      "Epoch 74/100\n",
      "64/64 - 0s - loss: 0.0028 - val_loss: 0.0122\n",
      "Epoch 75/100\n",
      "64/64 - 0s - loss: 0.0027 - val_loss: 0.0122\n",
      "Epoch 76/100\n",
      "64/64 - 0s - loss: 0.0028 - val_loss: 0.0121\n",
      "Epoch 77/100\n",
      "64/64 - 0s - loss: 0.0028 - val_loss: 0.0127\n",
      "Epoch 78/100\n",
      "64/64 - 0s - loss: 0.0033 - val_loss: 0.0124\n",
      "Epoch 79/100\n",
      "64/64 - 0s - loss: 0.0028 - val_loss: 0.0123\n",
      "Epoch 80/100\n",
      "64/64 - 0s - loss: 0.0027 - val_loss: 0.0120\n",
      "Epoch 81/100\n",
      "64/64 - 0s - loss: 0.0027 - val_loss: 0.0122\n",
      "Epoch 82/100\n",
      "64/64 - 0s - loss: 0.0027 - val_loss: 0.0119\n",
      "Epoch 83/100\n",
      "64/64 - 0s - loss: 0.0027 - val_loss: 0.0118\n",
      "Epoch 84/100\n",
      "64/64 - 0s - loss: 0.0027 - val_loss: 0.0120\n",
      "Epoch 85/100\n",
      "64/64 - 0s - loss: 0.0027 - val_loss: 0.0120\n",
      "Epoch 86/100\n",
      "64/64 - 0s - loss: 0.0028 - val_loss: 0.0123\n",
      "Epoch 87/100\n",
      "64/64 - 0s - loss: 0.0027 - val_loss: 0.0119\n",
      "Epoch 88/100\n",
      "64/64 - 0s - loss: 0.0027 - val_loss: 0.0120\n",
      "Epoch 89/100\n",
      "64/64 - 0s - loss: 0.0027 - val_loss: 0.0116\n",
      "Epoch 90/100\n",
      "64/64 - 0s - loss: 0.0026 - val_loss: 0.0117\n",
      "Epoch 91/100\n",
      "64/64 - 0s - loss: 0.0026 - val_loss: 0.0118\n",
      "Epoch 92/100\n",
      "64/64 - 0s - loss: 0.0025 - val_loss: 0.0120\n",
      "Epoch 93/100\n",
      "64/64 - 0s - loss: 0.0026 - val_loss: 0.0121\n",
      "Epoch 94/100\n",
      "64/64 - 0s - loss: 0.0026 - val_loss: 0.0117\n",
      "Epoch 95/100\n",
      "64/64 - 0s - loss: 0.0024 - val_loss: 0.0117\n",
      "Epoch 96/100\n",
      "64/64 - 0s - loss: 0.0027 - val_loss: 0.0117\n",
      "Epoch 97/100\n",
      "64/64 - 0s - loss: 0.0025 - val_loss: 0.0119\n",
      "Epoch 98/100\n",
      "64/64 - 0s - loss: 0.0024 - val_loss: 0.0120\n",
      "Epoch 99/100\n",
      "64/64 - 0s - loss: 0.0025 - val_loss: 0.0116\n",
      "Epoch 100/100\n",
      "64/64 - 0s - loss: 0.0024 - val_loss: 0.0116\n"
     ]
    }
   ],
   "source": [
    "#AUTOENCODER DATASET: COMPLETE\n",
    "\n",
    "# AutoEncoder Model Preparation\n",
    "n_inputs = X.shape[1]\n",
    "# define encoder\n",
    "input_data_shape= Input(shape=(n_inputs,))\n",
    "# encoder level 1\n",
    "encoder= Dense(n_inputs*0.8)(input_data_shape)\n",
    "encoder = BatchNormalization()(encoder)\n",
    "encoder= LeakyReLU()(encoder)\n",
    "# encoder level 2\n",
    "encoder= Dense(n_inputs*0.5)(encoder)\n",
    "encoder= BatchNormalization()(encoder)\n",
    "encoder= LeakyReLU()(encoder)\n",
    "# bottleneck\n",
    "n_bottleneck = round(float(n_inputs)*0.3)\n",
    "bottleneck = Dense(n_bottleneck)(encoder)\n",
    "# define decoder, level 1\n",
    "decoder = Dense(n_inputs*0.5)(bottleneck)\n",
    "decoder = BatchNormalization()(decoder)\n",
    "decoder = LeakyReLU()(decoder)\n",
    "# decoder level 2\n",
    "decoder = Dense(n_inputs*0.8)(decoder)\n",
    "decoder = BatchNormalization()(decoder)\n",
    "decoder = LeakyReLU()(decoder)\n",
    "\n",
    "# output layer\n",
    "output = Dense(n_inputs, activation='linear')(decoder)\n",
    "# define autoencoder model\n",
    "model = Model(inputs=input_data_shape, outputs=output)\n",
    "# compile autoencoder model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# fit the autoencoder model to reconstruct input\n",
    "history = model.fit(X_train, X_train, epochs=100, batch_size=16, verbose=2, validation_data=(X_test,X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "# save the encoder to file\n",
    "encoder = Model(inputs=input_data_shape, outputs=bottleneck)\n",
    "encoder.save('aaaaa.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x194222adcc8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "(1019, 230) (1019, 69)\n",
      "32/32 [==============================] - 0s 599us/step - loss: 0.1054 - accuracy: 0.8656\n",
      "32/32 [==============================] - 0s 552us/step - loss: 0.1163 - accuracy: 0.8430\n",
      "Accuracy: 86.56\n",
      "Accuracy with encoder: 84.30\n"
     ]
    }
   ],
   "source": [
    "#DATASET: COMPLETE\n",
    "\n",
    "# load the model from file\n",
    "encoder = load_model('encoder_normal.h5')\n",
    "\n",
    "#1.0 prepare the data\n",
    "features = np.array([f for f in data.columns if f not in [label]])\n",
    "X=data[features]\n",
    "X.to_numpy()\n",
    "y=data[label].map({'Positive': 0, 'Negative':1})\n",
    "y.to_numpy()\n",
    "\n",
    "# split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# scale data\n",
    "t = MinMaxScaler()\n",
    "t.fit(X_train)\n",
    "X_train = t.transform(X_train)\n",
    "X_test = t.transform(X_test)\n",
    "\n",
    "# encode the train data\n",
    "X_train_encode = encoder.predict(X_train)\n",
    "# encode the test data\n",
    "X_test_encode = encoder.predict(X_test)\n",
    "print(X_train.shape,X_train_encode.shape)\n",
    "\n",
    "#1.1 model with X_train\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the keras model\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=10,verbose=0)\n",
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X_train, y_train)\n",
    "\n",
    "#1.2 model with X_train_encode\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the keras model\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train_encode, y_train, epochs=150, batch_size=10,verbose=0)\n",
    "# evaluate the keras model\n",
    "_, accuracy_encode = model.evaluate(X_train_encode, y_train)\n",
    "\n",
    "#1.3 results\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n",
    "print('Accuracy with encoder: %.2f' % (accuracy_encode*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BORUTA\n",
    "\n",
    "#1.0 prepare the data\n",
    "feature_selection= pd.read_excel('L2_comp.xlsx', sep=';',decimal='.')\n",
    "boruta_selected=feature_selection[feature_selection['BORUTA']>=600]\n",
    "feature_selected_boruta=boruta_selected['features']\n",
    "X=data[feature_selected_boruta]\n",
    "X.to_numpy()\n",
    "y=data[label].map({'Positive': 0, 'Negative':1})\n",
    "y.to_numpy()\n",
    "\n",
    "# split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# scale data\n",
    "t = MinMaxScaler()\n",
    "t.fit(X_train)\n",
    "X_train = t.transform(X_train)\n",
    "X_test = t.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 63)]              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 50)                3200      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 31)                1581      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 31)                124       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 31)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 19)                608       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 31)                620       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 31)                124       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 31)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 50)                1600      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 63)                3213      \n",
      "=================================================================\n",
      "Total params: 11,470\n",
      "Trainable params: 11,146\n",
      "Non-trainable params: 324\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "64/64 - 1s - loss: 0.2269 - val_loss: 0.1213\n",
      "Epoch 2/100\n",
      "64/64 - 0s - loss: 0.0440 - val_loss: 0.0853\n",
      "Epoch 3/100\n",
      "64/64 - 0s - loss: 0.0295 - val_loss: 0.0733\n",
      "Epoch 4/100\n",
      "64/64 - 0s - loss: 0.0239 - val_loss: 0.0715\n",
      "Epoch 5/100\n",
      "64/64 - 0s - loss: 0.0217 - val_loss: 0.0680\n",
      "Epoch 6/100\n",
      "64/64 - 0s - loss: 0.0197 - val_loss: 0.0637\n",
      "Epoch 7/100\n",
      "64/64 - 0s - loss: 0.0188 - val_loss: 0.0637\n",
      "Epoch 8/100\n",
      "64/64 - 0s - loss: 0.0180 - val_loss: 0.0635\n",
      "Epoch 9/100\n",
      "64/64 - 0s - loss: 0.0174 - val_loss: 0.0607\n",
      "Epoch 10/100\n",
      "64/64 - 0s - loss: 0.0161 - val_loss: 0.0599\n",
      "Epoch 11/100\n",
      "64/64 - 0s - loss: 0.0161 - val_loss: 0.0611\n",
      "Epoch 12/100\n",
      "64/64 - 0s - loss: 0.0156 - val_loss: 0.0579\n",
      "Epoch 13/100\n",
      "64/64 - 0s - loss: 0.0153 - val_loss: 0.0551\n",
      "Epoch 14/100\n",
      "64/64 - 0s - loss: 0.0150 - val_loss: 0.0555\n",
      "Epoch 15/100\n",
      "64/64 - 0s - loss: 0.0150 - val_loss: 0.0547\n",
      "Epoch 16/100\n",
      "64/64 - 0s - loss: 0.0146 - val_loss: 0.0532\n",
      "Epoch 17/100\n",
      "64/64 - 0s - loss: 0.0141 - val_loss: 0.0543\n",
      "Epoch 18/100\n",
      "64/64 - 0s - loss: 0.0143 - val_loss: 0.0520\n",
      "Epoch 19/100\n",
      "64/64 - 0s - loss: 0.0136 - val_loss: 0.0518\n",
      "Epoch 20/100\n",
      "64/64 - 0s - loss: 0.0138 - val_loss: 0.0519\n",
      "Epoch 21/100\n",
      "64/64 - 0s - loss: 0.0131 - val_loss: 0.0504\n",
      "Epoch 22/100\n",
      "64/64 - 0s - loss: 0.0133 - val_loss: 0.0503\n",
      "Epoch 23/100\n",
      "64/64 - 0s - loss: 0.0131 - val_loss: 0.0509\n",
      "Epoch 24/100\n",
      "64/64 - 0s - loss: 0.0126 - val_loss: 0.0509\n",
      "Epoch 25/100\n",
      "64/64 - 0s - loss: 0.0130 - val_loss: 0.0497\n",
      "Epoch 26/100\n",
      "64/64 - 0s - loss: 0.0117 - val_loss: 0.0502\n",
      "Epoch 27/100\n",
      "64/64 - 0s - loss: 0.0118 - val_loss: 0.0499\n",
      "Epoch 28/100\n",
      "64/64 - 0s - loss: 0.0117 - val_loss: 0.0500\n",
      "Epoch 29/100\n",
      "64/64 - 0s - loss: 0.0116 - val_loss: 0.0497\n",
      "Epoch 30/100\n",
      "64/64 - 0s - loss: 0.0117 - val_loss: 0.0497\n",
      "Epoch 31/100\n",
      "64/64 - 0s - loss: 0.0115 - val_loss: 0.0492\n",
      "Epoch 32/100\n",
      "64/64 - 0s - loss: 0.0112 - val_loss: 0.0484\n",
      "Epoch 33/100\n",
      "64/64 - 0s - loss: 0.0113 - val_loss: 0.0481\n",
      "Epoch 34/100\n",
      "64/64 - 0s - loss: 0.0120 - val_loss: 0.0490\n",
      "Epoch 35/100\n",
      "64/64 - 0s - loss: 0.0110 - val_loss: 0.0482\n",
      "Epoch 36/100\n",
      "64/64 - 0s - loss: 0.0109 - val_loss: 0.0483\n",
      "Epoch 37/100\n",
      "64/64 - 0s - loss: 0.0107 - val_loss: 0.0485\n",
      "Epoch 38/100\n",
      "64/64 - 0s - loss: 0.0108 - val_loss: 0.0479\n",
      "Epoch 39/100\n",
      "64/64 - 0s - loss: 0.0104 - val_loss: 0.0479\n",
      "Epoch 40/100\n",
      "64/64 - 0s - loss: 0.0107 - val_loss: 0.0481\n",
      "Epoch 41/100\n",
      "64/64 - 0s - loss: 0.0102 - val_loss: 0.0477\n",
      "Epoch 42/100\n",
      "64/64 - 0s - loss: 0.0101 - val_loss: 0.0472\n",
      "Epoch 43/100\n",
      "64/64 - 0s - loss: 0.0098 - val_loss: 0.0471\n",
      "Epoch 44/100\n",
      "64/64 - 0s - loss: 0.0099 - val_loss: 0.0474\n",
      "Epoch 45/100\n",
      "64/64 - 0s - loss: 0.0098 - val_loss: 0.0471\n",
      "Epoch 46/100\n",
      "64/64 - 0s - loss: 0.0099 - val_loss: 0.0468\n",
      "Epoch 47/100\n",
      "64/64 - 0s - loss: 0.0096 - val_loss: 0.0475\n",
      "Epoch 48/100\n",
      "64/64 - 0s - loss: 0.0098 - val_loss: 0.0472\n",
      "Epoch 49/100\n",
      "64/64 - 0s - loss: 0.0096 - val_loss: 0.0464\n",
      "Epoch 50/100\n",
      "64/64 - 0s - loss: 0.0094 - val_loss: 0.0473\n",
      "Epoch 51/100\n",
      "64/64 - 0s - loss: 0.0097 - val_loss: 0.0465\n",
      "Epoch 52/100\n",
      "64/64 - 0s - loss: 0.0090 - val_loss: 0.0476\n",
      "Epoch 53/100\n",
      "64/64 - 0s - loss: 0.0097 - val_loss: 0.0485\n",
      "Epoch 54/100\n",
      "64/64 - 0s - loss: 0.0094 - val_loss: 0.0470\n",
      "Epoch 55/100\n",
      "64/64 - 0s - loss: 0.0091 - val_loss: 0.0464\n",
      "Epoch 56/100\n",
      "64/64 - 0s - loss: 0.0090 - val_loss: 0.0462\n",
      "Epoch 57/100\n",
      "64/64 - 0s - loss: 0.0088 - val_loss: 0.0464\n",
      "Epoch 58/100\n",
      "64/64 - 0s - loss: 0.0093 - val_loss: 0.0460\n",
      "Epoch 59/100\n",
      "64/64 - 0s - loss: 0.0087 - val_loss: 0.0459\n",
      "Epoch 60/100\n",
      "64/64 - 0s - loss: 0.0085 - val_loss: 0.0455\n",
      "Epoch 61/100\n",
      "64/64 - 0s - loss: 0.0084 - val_loss: 0.0452\n",
      "Epoch 62/100\n",
      "64/64 - 0s - loss: 0.0086 - val_loss: 0.0458\n",
      "Epoch 63/100\n",
      "64/64 - 0s - loss: 0.0083 - val_loss: 0.0460\n",
      "Epoch 64/100\n",
      "64/64 - 0s - loss: 0.0087 - val_loss: 0.0456\n",
      "Epoch 65/100\n",
      "64/64 - 0s - loss: 0.0083 - val_loss: 0.0455\n",
      "Epoch 66/100\n",
      "64/64 - 0s - loss: 0.0085 - val_loss: 0.0462\n",
      "Epoch 67/100\n",
      "64/64 - 0s - loss: 0.0081 - val_loss: 0.0449\n",
      "Epoch 68/100\n",
      "64/64 - 0s - loss: 0.0081 - val_loss: 0.0448\n",
      "Epoch 69/100\n",
      "64/64 - 0s - loss: 0.0082 - val_loss: 0.0450\n",
      "Epoch 70/100\n",
      "64/64 - 0s - loss: 0.0085 - val_loss: 0.0450\n",
      "Epoch 71/100\n",
      "64/64 - 0s - loss: 0.0084 - val_loss: 0.0454\n",
      "Epoch 72/100\n",
      "64/64 - 0s - loss: 0.0077 - val_loss: 0.0460\n",
      "Epoch 73/100\n",
      "64/64 - 0s - loss: 0.0077 - val_loss: 0.0458\n",
      "Epoch 74/100\n",
      "64/64 - 0s - loss: 0.0077 - val_loss: 0.0456\n",
      "Epoch 75/100\n",
      "64/64 - 0s - loss: 0.0075 - val_loss: 0.0455\n",
      "Epoch 76/100\n",
      "64/64 - 0s - loss: 0.0076 - val_loss: 0.0460\n",
      "Epoch 77/100\n",
      "64/64 - 0s - loss: 0.0078 - val_loss: 0.0456\n",
      "Epoch 78/100\n",
      "64/64 - 0s - loss: 0.0076 - val_loss: 0.0454\n",
      "Epoch 79/100\n",
      "64/64 - 0s - loss: 0.0078 - val_loss: 0.0453\n",
      "Epoch 80/100\n",
      "64/64 - 0s - loss: 0.0075 - val_loss: 0.0452\n",
      "Epoch 81/100\n",
      "64/64 - 0s - loss: 0.0075 - val_loss: 0.0449\n",
      "Epoch 82/100\n",
      "64/64 - 0s - loss: 0.0073 - val_loss: 0.0451\n",
      "Epoch 83/100\n",
      "64/64 - 0s - loss: 0.0076 - val_loss: 0.0452\n",
      "Epoch 84/100\n",
      "64/64 - 0s - loss: 0.0073 - val_loss: 0.0457\n",
      "Epoch 85/100\n",
      "64/64 - 0s - loss: 0.0072 - val_loss: 0.0460\n",
      "Epoch 86/100\n",
      "64/64 - 0s - loss: 0.0072 - val_loss: 0.0450\n",
      "Epoch 87/100\n",
      "64/64 - 0s - loss: 0.0074 - val_loss: 0.0445\n",
      "Epoch 88/100\n",
      "64/64 - 0s - loss: 0.0069 - val_loss: 0.0444\n",
      "Epoch 89/100\n",
      "64/64 - 0s - loss: 0.0091 - val_loss: 0.0452\n",
      "Epoch 90/100\n",
      "64/64 - 0s - loss: 0.0071 - val_loss: 0.0449\n",
      "Epoch 91/100\n",
      "64/64 - 0s - loss: 0.0073 - val_loss: 0.0440\n",
      "Epoch 92/100\n",
      "64/64 - 0s - loss: 0.0070 - val_loss: 0.0445\n",
      "Epoch 93/100\n",
      "64/64 - 0s - loss: 0.0069 - val_loss: 0.0448\n",
      "Epoch 94/100\n",
      "64/64 - 0s - loss: 0.0071 - val_loss: 0.0445\n",
      "Epoch 95/100\n",
      "64/64 - 0s - loss: 0.0069 - val_loss: 0.0438\n",
      "Epoch 96/100\n",
      "64/64 - 0s - loss: 0.0067 - val_loss: 0.0443\n",
      "Epoch 97/100\n",
      "64/64 - 0s - loss: 0.0066 - val_loss: 0.0444\n",
      "Epoch 98/100\n",
      "64/64 - 0s - loss: 0.0068 - val_loss: 0.0448\n",
      "Epoch 99/100\n",
      "64/64 - 0s - loss: 0.0067 - val_loss: 0.0441\n",
      "Epoch 100/100\n",
      "64/64 - 0s - loss: 0.0067 - val_loss: 0.0447\n"
     ]
    }
   ],
   "source": [
    "#AUTOENCODER DATASET: BORUTA\n",
    "\n",
    "# AutoEncoder Model Preparation\n",
    "n_inputs = X.shape[1]\n",
    "# define encoder\n",
    "input_data_shape= Input(shape=(n_inputs,))\n",
    "# encoder level 1\n",
    "encoder= Dense(n_inputs*0.8)(input_data_shape)\n",
    "encoder = BatchNormalization()(encoder)\n",
    "encoder= LeakyReLU()(encoder)\n",
    "# encoder level 2\n",
    "encoder= Dense(n_inputs*0.5)(encoder)\n",
    "encoder= BatchNormalization()(encoder)\n",
    "encoder= LeakyReLU()(encoder)\n",
    "# bottleneck\n",
    "n_bottleneck = round(float(n_inputs)*0.3)\n",
    "bottleneck = Dense(n_bottleneck)(encoder)\n",
    "# define decoder, level 1\n",
    "decoder = Dense(n_inputs*0.5)(bottleneck)\n",
    "decoder = BatchNormalization()(decoder)\n",
    "decoder = LeakyReLU()(decoder)\n",
    "# decoder level 2\n",
    "decoder = Dense(n_inputs*0.8)(decoder)\n",
    "decoder = BatchNormalization()(decoder)\n",
    "decoder = LeakyReLU()(decoder)\n",
    "\n",
    "# output layer\n",
    "output = Dense(n_inputs, activation='linear')(decoder)\n",
    "# define autoencoder model\n",
    "model = Model(inputs=input_data_shape, outputs=output)\n",
    "# compile autoencoder model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# fit the autoencoder model to reconstruct input\n",
    "history = model.fit(X_train, X_train, epochs=100, batch_size=16, verbose=2, validation_data=(X_test,X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "# save the encoder to file\n",
    "# save the encoder to file\n",
    "encoder = Model(inputs=input_data_shape, outputs=bottleneck)\n",
    "encoder.save('encoder_boruta.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "(1019, 63) (1019, 19)\n",
      "32/32 [==============================] - 0s 677us/step - loss: 0.1276 - accuracy: 0.8292\n",
      "32/32 [==============================] - 0s 804us/step - loss: 0.1467 - accuracy: 0.8037\n",
      "Accuracy: 82.92\n",
      "Accuracy with encoder: 80.37\n"
     ]
    }
   ],
   "source": [
    "#DATASET: BORUTA\n",
    "\n",
    "# load the model from file\n",
    "encoder = load_model('encoder_boruta.h5')\n",
    "\n",
    "#1.0 prepare the data\n",
    "feature_selection= pd.read_excel('L2_comp.xlsx', sep=';',decimal='.')\n",
    "boruta_selected=feature_selection[feature_selection['BORUTA']>=600]\n",
    "feature_selected_boruta=boruta_selected['features']\n",
    "X=data[feature_selected_boruta]\n",
    "X.to_numpy()\n",
    "y=data[label].map({'Positive': 0, 'Negative':1})\n",
    "y.to_numpy()\n",
    "\n",
    "# split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# scale data\n",
    "t = MinMaxScaler()\n",
    "t.fit(X_train)\n",
    "X_train = t.transform(X_train)\n",
    "X_test = t.transform(X_test)\n",
    "\n",
    "# encode the train data\n",
    "X_train_encode = encoder.predict(X_train)\n",
    "# encode the test data\n",
    "X_test_encode = encoder.predict(X_test)\n",
    "print(X_train.shape,X_train_encode.shape)\n",
    "\n",
    "#1.1 model with X_train\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the keras model\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=10,verbose=0)\n",
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X_train, y_train)\n",
    "\n",
    "#1.2 model with X_train_encode\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the keras model\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train_encode, y_train, epochs=150, batch_size=10,verbose=0)\n",
    "# evaluate the keras model\n",
    "_, accuracy_encode = model.evaluate(X_train_encode, y_train)\n",
    "\n",
    "#1.3 results\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n",
    "print('Accuracy with encoder: %.2f' % (accuracy_encode*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MRMR\n",
    "\n",
    "#1.0 prepare the data\n",
    "feature_selection= pd.read_excel('L2_comp.xlsx', sep=';',decimal='.')\n",
    "boruta_selected=feature_selection[feature_selection['MRMR']>=600]\n",
    "feature_selected_boruta=boruta_selected['features']\n",
    "X=data[feature_selected_boruta]\n",
    "X.to_numpy()\n",
    "y=data[label].map({'Positive': 0, 'Negative':1})\n",
    "y.to_numpy()\n",
    "\n",
    "# split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# scale data\n",
    "t = MinMaxScaler()\n",
    "t.fit(X_train)\n",
    "X_train = t.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 62)]              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 49)                3087      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 49)                196       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 49)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 31)                1550      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 31)                124       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 31)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 19)                608       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 31)                620       \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 31)                124       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 31)                0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 49)                1568      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 49)                196       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 49)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 62)                3100      \n",
      "=================================================================\n",
      "Total params: 11,173\n",
      "Trainable params: 10,853\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "64/64 - 1s - loss: 0.1898 - val_loss: 54.2805\n",
      "Epoch 2/100\n",
      "64/64 - 0s - loss: 0.0287 - val_loss: 52.4301\n",
      "Epoch 3/100\n",
      "64/64 - 0s - loss: 0.0145 - val_loss: 50.7457\n",
      "Epoch 4/100\n",
      "64/64 - 0s - loss: 0.0101 - val_loss: 48.7278\n",
      "Epoch 5/100\n",
      "64/64 - 0s - loss: 0.0083 - val_loss: 47.2352\n",
      "Epoch 6/100\n",
      "64/64 - 0s - loss: 0.0074 - val_loss: 46.5176\n",
      "Epoch 7/100\n",
      "64/64 - 0s - loss: 0.0063 - val_loss: 47.1407\n",
      "Epoch 8/100\n",
      "64/64 - 0s - loss: 0.0055 - val_loss: 46.5112\n",
      "Epoch 9/100\n",
      "64/64 - 0s - loss: 0.0050 - val_loss: 46.8724\n",
      "Epoch 10/100\n",
      "64/64 - 0s - loss: 0.0049 - val_loss: 45.3154\n",
      "Epoch 11/100\n",
      "64/64 - 0s - loss: 0.0046 - val_loss: 49.4276\n",
      "Epoch 12/100\n",
      "64/64 - 0s - loss: 0.0044 - val_loss: 51.7816\n",
      "Epoch 13/100\n",
      "64/64 - 0s - loss: 0.0041 - val_loss: 45.5549\n",
      "Epoch 14/100\n",
      "64/64 - 0s - loss: 0.0040 - val_loss: 42.5583\n",
      "Epoch 15/100\n",
      "64/64 - 0s - loss: 0.0038 - val_loss: 47.1740\n",
      "Epoch 16/100\n",
      "64/64 - 0s - loss: 0.0038 - val_loss: 42.4357\n",
      "Epoch 17/100\n",
      "64/64 - 0s - loss: 0.0037 - val_loss: 46.6875\n",
      "Epoch 18/100\n",
      "64/64 - 0s - loss: 0.0037 - val_loss: 42.2392\n",
      "Epoch 19/100\n",
      "64/64 - 0s - loss: 0.0036 - val_loss: 37.7165\n",
      "Epoch 20/100\n",
      "64/64 - 0s - loss: 0.0035 - val_loss: 40.0299\n",
      "Epoch 21/100\n",
      "64/64 - 0s - loss: 0.0035 - val_loss: 40.5064\n",
      "Epoch 22/100\n",
      "64/64 - 0s - loss: 0.0034 - val_loss: 39.6126\n",
      "Epoch 23/100\n",
      "64/64 - 0s - loss: 0.0033 - val_loss: 37.4378\n",
      "Epoch 24/100\n",
      "64/64 - 0s - loss: 0.0033 - val_loss: 39.1033\n",
      "Epoch 25/100\n",
      "64/64 - 0s - loss: 0.0033 - val_loss: 38.8963\n",
      "Epoch 26/100\n",
      "64/64 - 0s - loss: 0.0032 - val_loss: 36.8450\n",
      "Epoch 27/100\n",
      "64/64 - 0s - loss: 0.0031 - val_loss: 35.8497\n",
      "Epoch 28/100\n",
      "64/64 - 0s - loss: 0.0031 - val_loss: 32.9930\n",
      "Epoch 29/100\n",
      "64/64 - 0s - loss: 0.0031 - val_loss: 35.3961\n",
      "Epoch 30/100\n",
      "64/64 - 0s - loss: 0.0030 - val_loss: 35.0943\n",
      "Epoch 31/100\n",
      "64/64 - 0s - loss: 0.0030 - val_loss: 30.3968\n",
      "Epoch 32/100\n",
      "64/64 - 0s - loss: 0.0030 - val_loss: 35.9427\n",
      "Epoch 33/100\n",
      "64/64 - 0s - loss: 0.0029 - val_loss: 29.4275\n",
      "Epoch 34/100\n",
      "64/64 - 0s - loss: 0.0029 - val_loss: 29.1865\n",
      "Epoch 35/100\n",
      "64/64 - 0s - loss: 0.0029 - val_loss: 29.3236\n",
      "Epoch 36/100\n",
      "64/64 - 0s - loss: 0.0028 - val_loss: 28.8721\n",
      "Epoch 37/100\n",
      "64/64 - 0s - loss: 0.0027 - val_loss: 27.4385\n",
      "Epoch 38/100\n",
      "64/64 - 0s - loss: 0.0028 - val_loss: 26.3131\n",
      "Epoch 39/100\n",
      "64/64 - 0s - loss: 0.0027 - val_loss: 25.8782\n",
      "Epoch 40/100\n",
      "64/64 - 0s - loss: 0.0027 - val_loss: 24.6994\n",
      "Epoch 41/100\n",
      "64/64 - 0s - loss: 0.0026 - val_loss: 27.7607\n",
      "Epoch 42/100\n",
      "64/64 - 0s - loss: 0.0026 - val_loss: 23.2348\n",
      "Epoch 43/100\n",
      "64/64 - 0s - loss: 0.0027 - val_loss: 24.2123\n",
      "Epoch 44/100\n",
      "64/64 - 0s - loss: 0.0026 - val_loss: 23.9537\n",
      "Epoch 45/100\n",
      "64/64 - 0s - loss: 0.0026 - val_loss: 24.8204\n",
      "Epoch 46/100\n",
      "64/64 - 0s - loss: 0.0026 - val_loss: 27.2041\n",
      "Epoch 47/100\n",
      "64/64 - 0s - loss: 0.0026 - val_loss: 21.8553\n",
      "Epoch 48/100\n",
      "64/64 - 0s - loss: 0.0025 - val_loss: 22.9069\n",
      "Epoch 49/100\n",
      "64/64 - 0s - loss: 0.0024 - val_loss: 20.5941\n",
      "Epoch 50/100\n",
      "64/64 - 0s - loss: 0.0025 - val_loss: 20.3676\n",
      "Epoch 51/100\n",
      "64/64 - 0s - loss: 0.0025 - val_loss: 20.3247\n",
      "Epoch 52/100\n",
      "64/64 - 0s - loss: 0.0024 - val_loss: 19.3111\n",
      "Epoch 53/100\n",
      "64/64 - 0s - loss: 0.0024 - val_loss: 19.3108\n",
      "Epoch 54/100\n",
      "64/64 - 0s - loss: 0.0024 - val_loss: 24.4899\n",
      "Epoch 55/100\n",
      "64/64 - 0s - loss: 0.0023 - val_loss: 21.4273\n",
      "Epoch 56/100\n",
      "64/64 - 0s - loss: 0.0023 - val_loss: 21.2017\n",
      "Epoch 57/100\n",
      "64/64 - 0s - loss: 0.0023 - val_loss: 19.9364\n",
      "Epoch 58/100\n",
      "64/64 - 0s - loss: 0.0024 - val_loss: 22.1775\n",
      "Epoch 59/100\n",
      "64/64 - 0s - loss: 0.0024 - val_loss: 21.2259\n",
      "Epoch 60/100\n",
      "64/64 - 0s - loss: 0.0024 - val_loss: 18.2831\n",
      "Epoch 61/100\n",
      "64/64 - 0s - loss: 0.0023 - val_loss: 20.6460\n",
      "Epoch 62/100\n",
      "64/64 - 0s - loss: 0.0022 - val_loss: 18.0273\n",
      "Epoch 63/100\n",
      "64/64 - 0s - loss: 0.0022 - val_loss: 19.2880\n",
      "Epoch 64/100\n",
      "64/64 - 0s - loss: 0.0023 - val_loss: 22.1292\n",
      "Epoch 65/100\n",
      "64/64 - 0s - loss: 0.0023 - val_loss: 19.8769\n",
      "Epoch 66/100\n",
      "64/64 - 0s - loss: 0.0022 - val_loss: 18.4262\n",
      "Epoch 67/100\n",
      "64/64 - 0s - loss: 0.0022 - val_loss: 18.8999\n",
      "Epoch 68/100\n",
      "64/64 - 0s - loss: 0.0022 - val_loss: 22.5587\n",
      "Epoch 69/100\n",
      "64/64 - 0s - loss: 0.0022 - val_loss: 17.7000\n",
      "Epoch 70/100\n",
      "64/64 - 0s - loss: 0.0022 - val_loss: 17.2617\n",
      "Epoch 71/100\n",
      "64/64 - 0s - loss: 0.0021 - val_loss: 19.7027\n",
      "Epoch 72/100\n",
      "64/64 - 0s - loss: 0.0022 - val_loss: 17.2669\n",
      "Epoch 73/100\n",
      "64/64 - 0s - loss: 0.0022 - val_loss: 19.1262\n",
      "Epoch 74/100\n",
      "64/64 - 0s - loss: 0.0021 - val_loss: 19.7021\n",
      "Epoch 75/100\n",
      "64/64 - 0s - loss: 0.0020 - val_loss: 18.8024\n",
      "Epoch 76/100\n",
      "64/64 - 0s - loss: 0.0021 - val_loss: 18.9213\n",
      "Epoch 77/100\n",
      "64/64 - 0s - loss: 0.0021 - val_loss: 18.9541\n",
      "Epoch 78/100\n",
      "64/64 - 0s - loss: 0.0021 - val_loss: 15.0708\n",
      "Epoch 79/100\n",
      "64/64 - 0s - loss: 0.0021 - val_loss: 19.9449\n",
      "Epoch 80/100\n",
      "64/64 - 0s - loss: 0.0021 - val_loss: 16.8112\n",
      "Epoch 81/100\n",
      "64/64 - 0s - loss: 0.0020 - val_loss: 18.3747\n",
      "Epoch 82/100\n",
      "64/64 - 0s - loss: 0.0021 - val_loss: 20.7176\n",
      "Epoch 83/100\n",
      "64/64 - 0s - loss: 0.0020 - val_loss: 19.4988\n",
      "Epoch 84/100\n",
      "64/64 - 0s - loss: 0.0020 - val_loss: 19.5894\n",
      "Epoch 85/100\n",
      "64/64 - 0s - loss: 0.0020 - val_loss: 18.5147\n",
      "Epoch 86/100\n",
      "64/64 - 0s - loss: 0.0020 - val_loss: 19.8662\n",
      "Epoch 87/100\n",
      "64/64 - 0s - loss: 0.0019 - val_loss: 16.7407\n",
      "Epoch 88/100\n",
      "64/64 - 0s - loss: 0.0020 - val_loss: 15.9135\n",
      "Epoch 89/100\n",
      "64/64 - 0s - loss: 0.0019 - val_loss: 17.2220\n",
      "Epoch 90/100\n",
      "64/64 - 0s - loss: 0.0019 - val_loss: 19.1395\n",
      "Epoch 91/100\n",
      "64/64 - 0s - loss: 0.0019 - val_loss: 17.2716\n",
      "Epoch 92/100\n",
      "64/64 - 0s - loss: 0.0019 - val_loss: 16.7279\n",
      "Epoch 93/100\n",
      "64/64 - 0s - loss: 0.0019 - val_loss: 18.3565\n",
      "Epoch 94/100\n",
      "64/64 - 0s - loss: 0.0019 - val_loss: 18.7145\n",
      "Epoch 95/100\n",
      "64/64 - 0s - loss: 0.0018 - val_loss: 19.3014\n",
      "Epoch 96/100\n",
      "64/64 - 0s - loss: 0.0019 - val_loss: 18.9094\n",
      "Epoch 97/100\n",
      "64/64 - 0s - loss: 0.0019 - val_loss: 15.3949\n",
      "Epoch 98/100\n",
      "64/64 - 0s - loss: 0.0018 - val_loss: 20.3210\n",
      "Epoch 99/100\n",
      "64/64 - 0s - loss: 0.0018 - val_loss: 18.8821\n",
      "Epoch 100/100\n",
      "64/64 - 0s - loss: 0.0018 - val_loss: 19.0770\n"
     ]
    }
   ],
   "source": [
    "#AUTOENCODER DATASET: MRMR\n",
    "\n",
    "# AutoEncoder Model Preparation\n",
    "n_inputs = X.shape[1]\n",
    "# define encoder\n",
    "input_data_shape= Input(shape=(n_inputs,))\n",
    "# encoder level 1\n",
    "encoder= Dense(n_inputs*0.8)(input_data_shape)\n",
    "encoder = BatchNormalization()(encoder)\n",
    "encoder= LeakyReLU()(encoder)\n",
    "# encoder level 2\n",
    "encoder= Dense(n_inputs*0.5)(encoder)\n",
    "encoder= BatchNormalization()(encoder)\n",
    "encoder= LeakyReLU()(encoder)\n",
    "# bottleneck\n",
    "n_bottleneck = round(float(n_inputs)*0.3)\n",
    "bottleneck = Dense(n_bottleneck)(encoder)\n",
    "# define decoder, level 1\n",
    "decoder = Dense(n_inputs*0.5)(bottleneck)\n",
    "decoder = BatchNormalization()(decoder)\n",
    "decoder = LeakyReLU()(decoder)\n",
    "# decoder level 2\n",
    "decoder = Dense(n_inputs*0.8)(decoder)\n",
    "decoder = BatchNormalization()(decoder)\n",
    "decoder = LeakyReLU()(decoder)\n",
    "\n",
    "# output layer\n",
    "output = Dense(n_inputs, activation='linear')(decoder)\n",
    "# define autoencoder model\n",
    "model = Model(inputs=input_data_shape, outputs=output)\n",
    "# compile autoencoder model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# fit the autoencoder model to reconstruct input\n",
    "history = model.fit(X_train, X_train, epochs=100, batch_size=16, verbose=2, validation_data=(X_test,X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "# save the encoder to file\n",
    "# save the encoder to file\n",
    "encoder = Model(inputs=input_data_shape, outputs=bottleneck)\n",
    "encoder.save('encoder_mrmr.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "(1019, 62) (1019, 19)\n",
      "32/32 [==============================] - 0s 613us/step - loss: 0.1694 - accuracy: 0.7566\n",
      "32/32 [==============================] - 0s 740us/step - loss: 0.1603 - accuracy: 0.7704\n",
      "Accuracy: 75.66\n",
      "Accuracy with encoder: 77.04\n"
     ]
    }
   ],
   "source": [
    "#DATASET: MRMR\n",
    "\n",
    "# load the model from file\n",
    "encoder = load_model('encoder_mrmr.h5')\n",
    "\n",
    "#1.0 prepare the data\n",
    "feature_selection= pd.read_excel('L2_comp.xlsx', sep=';',decimal='.')\n",
    "boruta_selected=feature_selection[feature_selection['MRMR']>=600]\n",
    "feature_selected_boruta=boruta_selected['features']\n",
    "X=data[feature_selected_boruta]\n",
    "X.to_numpy()\n",
    "y=data[label].map({'Positive': 0, 'Negative':1})\n",
    "y.to_numpy()\n",
    "\n",
    "# split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# scale data\n",
    "t = MinMaxScaler()\n",
    "t.fit(X_train)\n",
    "X_train = t.transform(X_train)\n",
    "X_test = t.transform(X_test)\n",
    "\n",
    "# encode the train data\n",
    "X_train_encode = encoder.predict(X_train)\n",
    "# encode the test data\n",
    "X_test_encode = encoder.predict(X_test)\n",
    "print(X_train.shape,X_train_encode.shape)\n",
    "\n",
    "#1.1 model with X_train\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the keras model\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=10,verbose=0)\n",
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X_train, y_train)\n",
    "\n",
    "#1.2 model with X_train_encode\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the keras model\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train_encode, y_train, epochs=150, batch_size=10,verbose=0)\n",
    "# evaluate the keras model\n",
    "_, accuracy_encode = model.evaluate(X_train_encode, y_train)\n",
    "\n",
    "#1.3 results\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n",
    "print('Accuracy with encoder: %.2f' % (accuracy_encode*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNION BORUTA MRMR\n",
    "\n",
    "#1.0 prepare the data\n",
    "feature_selection= pd.read_excel('L2_comp.xlsx', sep=';',decimal='.')\n",
    "boruta_selected=feature_selection[feature_selection['UNION']>=600]\n",
    "feature_selected_boruta=boruta_selected['features']\n",
    "X=data[feature_selected_boruta]\n",
    "X.to_numpy()\n",
    "y=data[label].map({'Positive': 0, 'Negative':1})\n",
    "y.to_numpy()\n",
    "\n",
    "# split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# scale data\n",
    "t = MinMaxScaler()\n",
    "t.fit(X_train)\n",
    "X_train = t.transform(X_train)\n",
    "X_test = t.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 114)]             0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 91)                10465     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 91)                364       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 91)                0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 57)                5244      \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 57)                228       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 57)                0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 34)                1972      \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 57)                1995      \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 57)                228       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 57)                0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 91)                5278      \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 91)                364       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 91)                0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 114)               10488     \n",
      "=================================================================\n",
      "Total params: 36,626\n",
      "Trainable params: 36,034\n",
      "Non-trainable params: 592\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "64/64 - 1s - loss: 0.1468 - val_loss: 0.0634\n",
      "Epoch 2/100\n",
      "64/64 - 0s - loss: 0.0221 - val_loss: 0.0483\n",
      "Epoch 3/100\n",
      "64/64 - 0s - loss: 0.0160 - val_loss: 0.0408\n",
      "Epoch 4/100\n",
      "64/64 - 0s - loss: 0.0130 - val_loss: 0.0357\n",
      "Epoch 5/100\n",
      "64/64 - 0s - loss: 0.0123 - val_loss: 0.0334\n",
      "Epoch 6/100\n",
      "64/64 - 0s - loss: 0.0114 - val_loss: 0.0333\n",
      "Epoch 7/100\n",
      "64/64 - 0s - loss: 0.0109 - val_loss: 0.0321\n",
      "Epoch 8/100\n",
      "64/64 - 0s - loss: 0.0101 - val_loss: 0.0304\n",
      "Epoch 9/100\n",
      "64/64 - 0s - loss: 0.0102 - val_loss: 0.0306\n",
      "Epoch 10/100\n",
      "64/64 - 0s - loss: 0.0097 - val_loss: 0.0303\n",
      "Epoch 11/100\n",
      "64/64 - 0s - loss: 0.0095 - val_loss: 0.0300\n",
      "Epoch 12/100\n",
      "64/64 - 0s - loss: 0.0090 - val_loss: 0.0288\n",
      "Epoch 13/100\n",
      "64/64 - 0s - loss: 0.0088 - val_loss: 0.0292\n",
      "Epoch 14/100\n",
      "64/64 - 0s - loss: 0.0088 - val_loss: 0.0287\n",
      "Epoch 15/100\n",
      "64/64 - 0s - loss: 0.0084 - val_loss: 0.0287\n",
      "Epoch 16/100\n",
      "64/64 - 0s - loss: 0.0079 - val_loss: 0.0282\n",
      "Epoch 17/100\n",
      "64/64 - 0s - loss: 0.0081 - val_loss: 0.0274\n",
      "Epoch 18/100\n",
      "64/64 - 0s - loss: 0.0077 - val_loss: 0.0276\n",
      "Epoch 19/100\n",
      "64/64 - 0s - loss: 0.0077 - val_loss: 0.0277\n",
      "Epoch 20/100\n",
      "64/64 - 0s - loss: 0.0074 - val_loss: 0.0275\n",
      "Epoch 21/100\n",
      "64/64 - 0s - loss: 0.0075 - val_loss: 0.0278\n",
      "Epoch 22/100\n",
      "64/64 - 0s - loss: 0.0073 - val_loss: 0.0273\n",
      "Epoch 23/100\n",
      "64/64 - 0s - loss: 0.0072 - val_loss: 0.0277\n",
      "Epoch 24/100\n",
      "64/64 - 0s - loss: 0.0072 - val_loss: 0.0270\n",
      "Epoch 25/100\n",
      "64/64 - 0s - loss: 0.0071 - val_loss: 0.0268\n",
      "Epoch 26/100\n",
      "64/64 - 0s - loss: 0.0066 - val_loss: 0.0268\n",
      "Epoch 27/100\n",
      "64/64 - 0s - loss: 0.0065 - val_loss: 0.0267\n",
      "Epoch 28/100\n",
      "64/64 - 0s - loss: 0.0066 - val_loss: 0.0263\n",
      "Epoch 29/100\n",
      "64/64 - 0s - loss: 0.0066 - val_loss: 0.0265\n",
      "Epoch 30/100\n",
      "64/64 - 0s - loss: 0.0065 - val_loss: 0.0268\n",
      "Epoch 31/100\n",
      "64/64 - 0s - loss: 0.0064 - val_loss: 0.0264\n",
      "Epoch 32/100\n",
      "64/64 - 0s - loss: 0.0062 - val_loss: 0.0267\n",
      "Epoch 33/100\n",
      "64/64 - 0s - loss: 0.0061 - val_loss: 0.0269\n",
      "Epoch 34/100\n",
      "64/64 - 0s - loss: 0.0059 - val_loss: 0.0266\n",
      "Epoch 35/100\n",
      "64/64 - 0s - loss: 0.0060 - val_loss: 0.0263\n",
      "Epoch 36/100\n",
      "64/64 - 0s - loss: 0.0060 - val_loss: 0.0263\n",
      "Epoch 37/100\n",
      "64/64 - 0s - loss: 0.0056 - val_loss: 0.0264\n",
      "Epoch 38/100\n",
      "64/64 - 0s - loss: 0.0061 - val_loss: 0.0262\n",
      "Epoch 39/100\n",
      "64/64 - 0s - loss: 0.0057 - val_loss: 0.0256\n",
      "Epoch 40/100\n",
      "64/64 - 0s - loss: 0.0056 - val_loss: 0.0255\n",
      "Epoch 41/100\n",
      "64/64 - 0s - loss: 0.0056 - val_loss: 0.0261\n",
      "Epoch 42/100\n",
      "64/64 - 0s - loss: 0.0056 - val_loss: 0.0263\n",
      "Epoch 43/100\n",
      "64/64 - 0s - loss: 0.0056 - val_loss: 0.0258\n",
      "Epoch 44/100\n",
      "64/64 - 0s - loss: 0.0055 - val_loss: 0.0258\n",
      "Epoch 45/100\n",
      "64/64 - 0s - loss: 0.0054 - val_loss: 0.0252\n",
      "Epoch 46/100\n",
      "64/64 - 0s - loss: 0.0052 - val_loss: 0.0254\n",
      "Epoch 47/100\n",
      "64/64 - 0s - loss: 0.0053 - val_loss: 0.0258\n",
      "Epoch 48/100\n",
      "64/64 - 0s - loss: 0.0053 - val_loss: 0.0254\n",
      "Epoch 49/100\n",
      "64/64 - 0s - loss: 0.0050 - val_loss: 0.0254\n",
      "Epoch 50/100\n",
      "64/64 - 0s - loss: 0.0052 - val_loss: 0.0253\n",
      "Epoch 51/100\n",
      "64/64 - 0s - loss: 0.0053 - val_loss: 0.0251\n",
      "Epoch 52/100\n",
      "64/64 - 0s - loss: 0.0051 - val_loss: 0.0246\n",
      "Epoch 53/100\n",
      "64/64 - 0s - loss: 0.0051 - val_loss: 0.0252\n",
      "Epoch 54/100\n",
      "64/64 - 0s - loss: 0.0051 - val_loss: 0.0249\n",
      "Epoch 55/100\n",
      "64/64 - 0s - loss: 0.0049 - val_loss: 0.0245\n",
      "Epoch 56/100\n",
      "64/64 - 0s - loss: 0.0049 - val_loss: 0.0245\n",
      "Epoch 57/100\n",
      "64/64 - 0s - loss: 0.0049 - val_loss: 0.0244\n",
      "Epoch 58/100\n",
      "64/64 - 0s - loss: 0.0048 - val_loss: 0.0242\n",
      "Epoch 59/100\n",
      "64/64 - 0s - loss: 0.0047 - val_loss: 0.0241\n",
      "Epoch 60/100\n",
      "64/64 - 0s - loss: 0.0047 - val_loss: 0.0248\n",
      "Epoch 61/100\n",
      "64/64 - 0s - loss: 0.0045 - val_loss: 0.0246\n",
      "Epoch 62/100\n",
      "64/64 - 0s - loss: 0.0045 - val_loss: 0.0245\n",
      "Epoch 63/100\n",
      "64/64 - 0s - loss: 0.0046 - val_loss: 0.0241\n",
      "Epoch 64/100\n",
      "64/64 - 0s - loss: 0.0048 - val_loss: 0.0242\n",
      "Epoch 65/100\n",
      "64/64 - 0s - loss: 0.0045 - val_loss: 0.0241\n",
      "Epoch 66/100\n",
      "64/64 - 0s - loss: 0.0045 - val_loss: 0.0236\n",
      "Epoch 67/100\n",
      "64/64 - 0s - loss: 0.0045 - val_loss: 0.0243\n",
      "Epoch 68/100\n",
      "64/64 - 0s - loss: 0.0044 - val_loss: 0.0239\n",
      "Epoch 69/100\n",
      "64/64 - 0s - loss: 0.0045 - val_loss: 0.0241\n",
      "Epoch 70/100\n",
      "64/64 - 0s - loss: 0.0045 - val_loss: 0.0241\n",
      "Epoch 71/100\n",
      "64/64 - 0s - loss: 0.0044 - val_loss: 0.0237\n",
      "Epoch 72/100\n",
      "64/64 - 0s - loss: 0.0045 - val_loss: 0.0238\n",
      "Epoch 73/100\n",
      "64/64 - 0s - loss: 0.0044 - val_loss: 0.0237\n",
      "Epoch 74/100\n",
      "64/64 - 0s - loss: 0.0044 - val_loss: 0.0237\n",
      "Epoch 75/100\n",
      "64/64 - 0s - loss: 0.0043 - val_loss: 0.0241\n",
      "Epoch 76/100\n",
      "64/64 - 0s - loss: 0.0042 - val_loss: 0.0234\n",
      "Epoch 77/100\n",
      "64/64 - 0s - loss: 0.0042 - val_loss: 0.0235\n",
      "Epoch 78/100\n",
      "64/64 - 0s - loss: 0.0042 - val_loss: 0.0238\n",
      "Epoch 79/100\n",
      "64/64 - 0s - loss: 0.0041 - val_loss: 0.0237\n",
      "Epoch 80/100\n",
      "64/64 - 0s - loss: 0.0043 - val_loss: 0.0237\n",
      "Epoch 81/100\n",
      "64/64 - 0s - loss: 0.0042 - val_loss: 0.0233\n",
      "Epoch 82/100\n",
      "64/64 - 0s - loss: 0.0041 - val_loss: 0.0237\n",
      "Epoch 83/100\n",
      "64/64 - 0s - loss: 0.0042 - val_loss: 0.0236\n",
      "Epoch 84/100\n",
      "64/64 - 0s - loss: 0.0042 - val_loss: 0.0234\n",
      "Epoch 85/100\n",
      "64/64 - 0s - loss: 0.0039 - val_loss: 0.0234\n",
      "Epoch 86/100\n",
      "64/64 - 0s - loss: 0.0039 - val_loss: 0.0237\n",
      "Epoch 87/100\n",
      "64/64 - 0s - loss: 0.0040 - val_loss: 0.0234\n",
      "Epoch 88/100\n",
      "64/64 - 0s - loss: 0.0040 - val_loss: 0.0234\n",
      "Epoch 89/100\n",
      "64/64 - 0s - loss: 0.0039 - val_loss: 0.0234\n",
      "Epoch 90/100\n",
      "64/64 - 0s - loss: 0.0040 - val_loss: 0.0235\n",
      "Epoch 91/100\n",
      "64/64 - 0s - loss: 0.0041 - val_loss: 0.0235\n",
      "Epoch 92/100\n",
      "64/64 - 0s - loss: 0.0039 - val_loss: 0.0232\n",
      "Epoch 93/100\n",
      "64/64 - 0s - loss: 0.0039 - val_loss: 0.0232\n",
      "Epoch 94/100\n",
      "64/64 - 0s - loss: 0.0040 - val_loss: 0.0230\n",
      "Epoch 95/100\n",
      "64/64 - 0s - loss: 0.0039 - val_loss: 0.0234\n",
      "Epoch 96/100\n",
      "64/64 - 0s - loss: 0.0040 - val_loss: 0.0233\n",
      "Epoch 97/100\n",
      "64/64 - 0s - loss: 0.0038 - val_loss: 0.0230\n",
      "Epoch 98/100\n",
      "64/64 - 0s - loss: 0.0039 - val_loss: 0.0229\n",
      "Epoch 99/100\n",
      "64/64 - 0s - loss: 0.0038 - val_loss: 0.0230\n",
      "Epoch 100/100\n",
      "64/64 - 0s - loss: 0.0038 - val_loss: 0.0231\n"
     ]
    }
   ],
   "source": [
    "#AUTOENCODER DATASET: UNION\n",
    "\n",
    "# AutoEncoder Model Preparation\n",
    "n_inputs = X.shape[1]\n",
    "# define encoder\n",
    "input_data_shape= Input(shape=(n_inputs,))\n",
    "# encoder level 1\n",
    "encoder= Dense(n_inputs*0.8)(input_data_shape)\n",
    "encoder = BatchNormalization()(encoder)\n",
    "encoder= LeakyReLU()(encoder)\n",
    "# encoder level 2\n",
    "encoder= Dense(n_inputs*0.5)(encoder)\n",
    "encoder= BatchNormalization()(encoder)\n",
    "encoder= LeakyReLU()(encoder)\n",
    "# bottleneck\n",
    "n_bottleneck = round(float(n_inputs)*0.3)\n",
    "bottleneck = Dense(n_bottleneck)(encoder)\n",
    "# define decoder, level 1\n",
    "decoder = Dense(n_inputs*0.5)(bottleneck)\n",
    "decoder = BatchNormalization()(decoder)\n",
    "decoder = LeakyReLU()(decoder)\n",
    "# decoder level 2\n",
    "decoder = Dense(n_inputs*0.8)(decoder)\n",
    "decoder = BatchNormalization()(decoder)\n",
    "decoder = LeakyReLU()(decoder)\n",
    "\n",
    "# output layer\n",
    "output = Dense(n_inputs, activation='linear')(decoder)\n",
    "# define autoencoder model\n",
    "model = Model(inputs=input_data_shape, outputs=output)\n",
    "# compile autoencoder model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# fit the autoencoder model to reconstruct input\n",
    "history = model.fit(X_train, X_train, epochs=100, batch_size=16, verbose=2, validation_data=(X_test,X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "# save the encoder to file\n",
    "# save the encoder to file\n",
    "encoder = Model(inputs=input_data_shape, outputs=bottleneck)\n",
    "encoder.save('encoder_union.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INTERSECT BORUTA MRMR\n",
    "\n",
    "#1.0 prepare the data\n",
    "feature_selection= pd.read_excel('L2_comp.xlsx', sep=';',decimal='.')\n",
    "boruta_selected=feature_selection[feature_selection['INTERSECT']>=600]\n",
    "feature_selected_boruta=boruta_selected['features']\n",
    "X=data[feature_selected_boruta]\n",
    "X.to_numpy()\n",
    "y=data[label].map({'Positive': 0, 'Negative':1})\n",
    "y.to_numpy()\n",
    "\n",
    "# split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# scale data\n",
    "t = MinMaxScaler()\n",
    "t.fit(X_train)\n",
    "X_train = t.transform(X_train)\n",
    "X_test = t.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 13)]              0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 10)                140       \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 6)                 66        \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 4)                 28        \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 6)                 30        \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 10)                70        \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 13)                143       \n",
      "=================================================================\n",
      "Total params: 605\n",
      "Trainable params: 541\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "64/64 - 1s - loss: 0.4010 - val_loss: 0.1935\n",
      "Epoch 2/100\n",
      "64/64 - 0s - loss: 0.1810 - val_loss: 0.1555\n",
      "Epoch 3/100\n",
      "64/64 - 0s - loss: 0.0872 - val_loss: 0.1279\n",
      "Epoch 4/100\n",
      "64/64 - 0s - loss: 0.0432 - val_loss: 0.1211\n",
      "Epoch 5/100\n",
      "64/64 - 0s - loss: 0.0254 - val_loss: 0.1377\n",
      "Epoch 6/100\n",
      "64/64 - 0s - loss: 0.0185 - val_loss: 0.1615\n",
      "Epoch 7/100\n",
      "64/64 - 0s - loss: 0.0161 - val_loss: 0.1816\n",
      "Epoch 8/100\n",
      "64/64 - 0s - loss: 0.0145 - val_loss: 0.1833\n",
      "Epoch 9/100\n",
      "64/64 - 0s - loss: 0.0136 - val_loss: 0.1734\n",
      "Epoch 10/100\n",
      "64/64 - 0s - loss: 0.0139 - val_loss: 0.1595\n",
      "Epoch 11/100\n",
      "64/64 - 0s - loss: 0.0130 - val_loss: 0.1519\n",
      "Epoch 12/100\n",
      "64/64 - 0s - loss: 0.0126 - val_loss: 0.1395\n",
      "Epoch 13/100\n",
      "64/64 - 0s - loss: 0.0126 - val_loss: 0.1406\n",
      "Epoch 14/100\n",
      "64/64 - 0s - loss: 0.0123 - val_loss: 0.1338\n",
      "Epoch 15/100\n",
      "64/64 - 0s - loss: 0.0118 - val_loss: 0.1286\n",
      "Epoch 16/100\n",
      "64/64 - 0s - loss: 0.0117 - val_loss: 0.1256\n",
      "Epoch 17/100\n",
      "64/64 - 0s - loss: 0.0115 - val_loss: 0.1324\n",
      "Epoch 18/100\n",
      "64/64 - 0s - loss: 0.0117 - val_loss: 0.1259\n",
      "Epoch 19/100\n",
      "64/64 - 0s - loss: 0.0113 - val_loss: 0.1203\n",
      "Epoch 20/100\n",
      "64/64 - 0s - loss: 0.0111 - val_loss: 0.1150\n",
      "Epoch 21/100\n",
      "64/64 - 0s - loss: 0.0109 - val_loss: 0.1231\n",
      "Epoch 22/100\n",
      "64/64 - 0s - loss: 0.0108 - val_loss: 0.1204\n",
      "Epoch 23/100\n",
      "64/64 - 0s - loss: 0.0108 - val_loss: 0.1167\n",
      "Epoch 24/100\n",
      "64/64 - 0s - loss: 0.0107 - val_loss: 0.1102\n",
      "Epoch 25/100\n",
      "64/64 - 0s - loss: 0.0104 - val_loss: 0.1123\n",
      "Epoch 26/100\n",
      "64/64 - 0s - loss: 0.0103 - val_loss: 0.1072\n",
      "Epoch 27/100\n",
      "64/64 - 0s - loss: 0.0103 - val_loss: 0.1071\n",
      "Epoch 28/100\n",
      "64/64 - 0s - loss: 0.0105 - val_loss: 0.1023\n",
      "Epoch 29/100\n",
      "64/64 - 0s - loss: 0.0100 - val_loss: 0.1062\n",
      "Epoch 30/100\n",
      "64/64 - 0s - loss: 0.0105 - val_loss: 0.1028\n",
      "Epoch 31/100\n",
      "64/64 - 0s - loss: 0.0101 - val_loss: 0.1064\n",
      "Epoch 32/100\n",
      "64/64 - 0s - loss: 0.0098 - val_loss: 0.1022\n",
      "Epoch 33/100\n",
      "64/64 - 0s - loss: 0.0098 - val_loss: 0.1025\n",
      "Epoch 34/100\n",
      "64/64 - 0s - loss: 0.0097 - val_loss: 0.1015\n",
      "Epoch 35/100\n",
      "64/64 - 0s - loss: 0.0098 - val_loss: 0.1022\n",
      "Epoch 36/100\n",
      "64/64 - 0s - loss: 0.0098 - val_loss: 0.1020\n",
      "Epoch 37/100\n",
      "64/64 - 0s - loss: 0.0094 - val_loss: 0.0986\n",
      "Epoch 38/100\n",
      "64/64 - 0s - loss: 0.0094 - val_loss: 0.0970\n",
      "Epoch 39/100\n",
      "64/64 - 0s - loss: 0.0091 - val_loss: 0.1014\n",
      "Epoch 40/100\n",
      "64/64 - 0s - loss: 0.0091 - val_loss: 0.0994\n",
      "Epoch 41/100\n",
      "64/64 - 0s - loss: 0.0092 - val_loss: 0.1055\n",
      "Epoch 42/100\n",
      "64/64 - 0s - loss: 0.0093 - val_loss: 0.1027\n",
      "Epoch 43/100\n",
      "64/64 - 0s - loss: 0.0091 - val_loss: 0.1043\n",
      "Epoch 44/100\n",
      "64/64 - 0s - loss: 0.0087 - val_loss: 0.1046\n",
      "Epoch 45/100\n",
      "64/64 - 0s - loss: 0.0089 - val_loss: 0.1098\n",
      "Epoch 46/100\n",
      "64/64 - 0s - loss: 0.0086 - val_loss: 0.1122\n",
      "Epoch 47/100\n",
      "64/64 - 0s - loss: 0.0085 - val_loss: 0.1175\n",
      "Epoch 48/100\n",
      "64/64 - 0s - loss: 0.0085 - val_loss: 0.1111\n",
      "Epoch 49/100\n",
      "64/64 - 0s - loss: 0.0084 - val_loss: 0.1204\n",
      "Epoch 50/100\n",
      "64/64 - 0s - loss: 0.0081 - val_loss: 0.1241\n",
      "Epoch 51/100\n",
      "64/64 - 0s - loss: 0.0083 - val_loss: 0.1181\n",
      "Epoch 52/100\n",
      "64/64 - 0s - loss: 0.0080 - val_loss: 0.1143\n",
      "Epoch 53/100\n",
      "64/64 - 0s - loss: 0.0078 - val_loss: 0.1194\n",
      "Epoch 54/100\n",
      "64/64 - 0s - loss: 0.0082 - val_loss: 0.1228\n",
      "Epoch 55/100\n",
      "64/64 - 0s - loss: 0.0078 - val_loss: 0.0992\n",
      "Epoch 56/100\n",
      "64/64 - 0s - loss: 0.0081 - val_loss: 0.1136\n",
      "Epoch 57/100\n",
      "64/64 - 0s - loss: 0.0078 - val_loss: 0.1089\n",
      "Epoch 58/100\n",
      "64/64 - 0s - loss: 0.0075 - val_loss: 0.1156\n",
      "Epoch 59/100\n",
      "64/64 - 0s - loss: 0.0076 - val_loss: 0.1063\n",
      "Epoch 60/100\n",
      "64/64 - 0s - loss: 0.0077 - val_loss: 0.1066\n",
      "Epoch 61/100\n",
      "64/64 - 0s - loss: 0.0077 - val_loss: 0.1102\n",
      "Epoch 62/100\n",
      "64/64 - 0s - loss: 0.0074 - val_loss: 0.1073\n",
      "Epoch 63/100\n",
      "64/64 - 0s - loss: 0.0073 - val_loss: 0.1062\n",
      "Epoch 64/100\n",
      "64/64 - 0s - loss: 0.0073 - val_loss: 0.1066\n",
      "Epoch 65/100\n",
      "64/64 - 0s - loss: 0.0072 - val_loss: 0.1023\n",
      "Epoch 66/100\n",
      "64/64 - 0s - loss: 0.0072 - val_loss: 0.1019\n",
      "Epoch 67/100\n",
      "64/64 - 0s - loss: 0.0071 - val_loss: 0.0976\n",
      "Epoch 68/100\n",
      "64/64 - 0s - loss: 0.0071 - val_loss: 0.1073\n",
      "Epoch 69/100\n",
      "64/64 - 0s - loss: 0.0071 - val_loss: 0.1119\n",
      "Epoch 70/100\n",
      "64/64 - 0s - loss: 0.0073 - val_loss: 0.1071\n",
      "Epoch 71/100\n",
      "64/64 - 0s - loss: 0.0068 - val_loss: 0.1086\n",
      "Epoch 72/100\n",
      "64/64 - 0s - loss: 0.0069 - val_loss: 0.0946\n",
      "Epoch 73/100\n",
      "64/64 - 0s - loss: 0.0071 - val_loss: 0.1069\n",
      "Epoch 74/100\n",
      "64/64 - 0s - loss: 0.0066 - val_loss: 0.1054\n",
      "Epoch 75/100\n",
      "64/64 - 0s - loss: 0.0069 - val_loss: 0.0957\n",
      "Epoch 76/100\n",
      "64/64 - 0s - loss: 0.0069 - val_loss: 0.1019\n",
      "Epoch 77/100\n",
      "64/64 - 0s - loss: 0.0066 - val_loss: 0.0981\n",
      "Epoch 78/100\n",
      "64/64 - 0s - loss: 0.0065 - val_loss: 0.0920\n",
      "Epoch 79/100\n",
      "64/64 - 0s - loss: 0.0065 - val_loss: 0.1034\n",
      "Epoch 80/100\n",
      "64/64 - 0s - loss: 0.0068 - val_loss: 0.1008\n",
      "Epoch 81/100\n",
      "64/64 - 0s - loss: 0.0067 - val_loss: 0.0994\n",
      "Epoch 82/100\n",
      "64/64 - 0s - loss: 0.0065 - val_loss: 0.0951\n",
      "Epoch 83/100\n",
      "64/64 - 0s - loss: 0.0065 - val_loss: 0.0879\n",
      "Epoch 84/100\n",
      "64/64 - 0s - loss: 0.0064 - val_loss: 0.0941\n",
      "Epoch 85/100\n",
      "64/64 - 0s - loss: 0.0065 - val_loss: 0.0924\n",
      "Epoch 86/100\n",
      "64/64 - 0s - loss: 0.0062 - val_loss: 0.0933\n",
      "Epoch 87/100\n",
      "64/64 - 0s - loss: 0.0062 - val_loss: 0.0877\n",
      "Epoch 88/100\n",
      "64/64 - 0s - loss: 0.0063 - val_loss: 0.0888\n",
      "Epoch 89/100\n",
      "64/64 - 0s - loss: 0.0063 - val_loss: 0.0907\n",
      "Epoch 90/100\n",
      "64/64 - 0s - loss: 0.0062 - val_loss: 0.0926\n",
      "Epoch 91/100\n",
      "64/64 - 0s - loss: 0.0064 - val_loss: 0.0906\n",
      "Epoch 92/100\n",
      "64/64 - 0s - loss: 0.0063 - val_loss: 0.0911\n",
      "Epoch 93/100\n",
      "64/64 - 0s - loss: 0.0060 - val_loss: 0.0876\n",
      "Epoch 94/100\n",
      "64/64 - 0s - loss: 0.0060 - val_loss: 0.0893\n",
      "Epoch 95/100\n",
      "64/64 - 0s - loss: 0.0061 - val_loss: 0.0922\n",
      "Epoch 96/100\n",
      "64/64 - 0s - loss: 0.0061 - val_loss: 0.0887\n",
      "Epoch 97/100\n",
      "64/64 - 0s - loss: 0.0065 - val_loss: 0.0933\n",
      "Epoch 98/100\n",
      "64/64 - 0s - loss: 0.0061 - val_loss: 0.0880\n",
      "Epoch 99/100\n",
      "64/64 - 0s - loss: 0.0059 - val_loss: 0.0871\n",
      "Epoch 100/100\n",
      "64/64 - 0s - loss: 0.0063 - val_loss: 0.0867\n"
     ]
    }
   ],
   "source": [
    "#AUTOENCODER DATASET: INTERSECT\n",
    "\n",
    "# AutoEncoder Model Preparation\n",
    "n_inputs = X.shape[1]\n",
    "# define encoder\n",
    "input_data_shape= Input(shape=(n_inputs,))\n",
    "# encoder level 1\n",
    "encoder= Dense(n_inputs*0.8)(input_data_shape)\n",
    "encoder = BatchNormalization()(encoder)\n",
    "encoder= LeakyReLU()(encoder)\n",
    "# encoder level 2\n",
    "encoder= Dense(n_inputs*0.5)(encoder)\n",
    "encoder= BatchNormalization()(encoder)\n",
    "encoder= LeakyReLU()(encoder)\n",
    "# bottleneck\n",
    "n_bottleneck = round(float(n_inputs)*0.3)\n",
    "bottleneck = Dense(n_bottleneck)(encoder)\n",
    "# define decoder, level 1\n",
    "decoder = Dense(n_inputs*0.5)(bottleneck)\n",
    "decoder = BatchNormalization()(decoder)\n",
    "decoder = LeakyReLU()(decoder)\n",
    "# decoder level 2\n",
    "decoder = Dense(n_inputs*0.8)(decoder)\n",
    "decoder = BatchNormalization()(decoder)\n",
    "decoder = LeakyReLU()(decoder)\n",
    "\n",
    "# output layer\n",
    "output = Dense(n_inputs, activation='linear')(decoder)\n",
    "# define autoencoder model\n",
    "model = Model(inputs=input_data_shape, outputs=output)\n",
    "# compile autoencoder model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# fit the autoencoder model to reconstruct input\n",
    "history = model.fit(X_train, X_train, epochs=100, batch_size=16, verbose=2, validation_data=(X_test,X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "# save the encoder to file\n",
    "# save the encoder to file\n",
    "encoder = Model(inputs=input_data_shape, outputs=bottleneck)\n",
    "encoder.save('encoder_intersect.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIT SU TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy WITHOUT encoder:       0.6219592373438527\n",
      "accuracy WITH encoder:          0.6232741617357002\n",
      "f1 score WITHOUT encoder:       0.4891432392173472\n",
      "f1 score WITH encoder:          0.48185716052369115\n",
      "precision WITHOUT encoder:      0.585643843336151\n",
      "precision WITH encoder:         0.689837785514668\n",
      "recall WITHOUT encoder:         0.6219592373438527\n",
      "recall WITH encoder:            0.6232741617357002\n",
      "roc auc score WITHOUT encoder:  0.5042576058201058\n",
      "roc auc score WITH encoder:     0.5029431216931217\n"
     ]
    }
   ],
   "source": [
    "#COMPLETE\n",
    "normal_acc=[]\n",
    "encoder_acc=[]\n",
    "# load the model from file\n",
    "encoder = load_model('encoder_normal.h5',compile=False)\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "features = np.array([f for f in data.columns if f not in [label]])\n",
    "X=data[features]\n",
    "X=X.to_numpy()\n",
    "y=data[label].map({'Positive': 0, 'Negative':1})\n",
    "y=y.to_numpy()\n",
    "y_pred=y-y\n",
    "y_pred=y_pred.reshape(-1,1)\n",
    "y_pred_encode=y-y\n",
    "y_pred_encode=y_pred_encode.reshape(-1,1)\n",
    "for x in y_pred:\n",
    "    if x==1:\n",
    "        print(\"aaaaaaa\")\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    \n",
    "    # mi creo i punti di train e di test\n",
    "    X_train, X_test = X[train_index,:], X[test_index,:]\n",
    "    #creo le label del train e quelle del test\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    # scale data\n",
    "    t = MinMaxScaler()\n",
    "    t.fit(X_train)\n",
    "    X_train = t.transform(X_train)\n",
    "    X_test = t.transform(X_test)\n",
    "\n",
    "    # encode the train data\n",
    "    X_train_encode = encoder.predict(X_train)\n",
    "    # encode the test data\n",
    "    X_test_encode = encoder.predict(X_test)\n",
    "    \n",
    "    #1.1 model with X_train\n",
    "    # define the keras model\n",
    "    model=Sequential()\n",
    "    model.add(Dense(12, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile the keras model\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit the keras model on the dataset\n",
    "    model.fit(X_train, y_train, epochs=150, batch_size=10,verbose=0)\n",
    "    # evaluate the keras model\n",
    "    #_, accuracy = model.evaluate(X_test, y_test)\n",
    "    #normal_acc.append(accuracy)\n",
    "    y_pred[test_index]=model.predict(X_test)\n",
    "    \n",
    "    #1.2 model with X_train_encode\n",
    "    # define the keras model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile the keras model\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit the keras model on the dataset\n",
    "    model.fit(X_train_encode, y_train, epochs=150, batch_size=10,verbose=0)\n",
    "    # evaluate the keras model\n",
    "    #_, accuracy_encode = model.evaluate(X_test_encode, y_test)\n",
    "    #encoder_acc.append(accuracy_encode)\n",
    "    y_pred_encode[test_index]=model.predict(X_test_encode)\n",
    "    \n",
    "print(\"accuracy WITHOUT encoder:      \",accuracy_score(y,y_pred))\n",
    "print(\"accuracy WITH encoder:         \",accuracy_score(y,y_pred_encode))\n",
    "print(\"f1 score WITHOUT encoder:      \",f1_score(y, y_pred, average='weighted'))\n",
    "print(\"f1 score WITH encoder:         \",f1_score(y, y_pred_encode, average='weighted'))\n",
    "print(\"precision WITHOUT encoder:     \",precision_score(y, y_pred, average='weighted'))\n",
    "print(\"precision WITH encoder:        \",precision_score(y, y_pred_encode, average='weighted'))\n",
    "print(\"recall WITHOUT encoder:        \",recall_score(y, y_pred, average='weighted'))\n",
    "print(\"recall WITH encoder:           \",recall_score(y, y_pred_encode, average='weighted'))\n",
    "print(\"roc auc score WITHOUT encoder: \",roc_auc_score(y, y_pred))\n",
    "print(\"roc auc score WITH encoder:    \",roc_auc_score(y, y_pred_encode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy WITHOUT encoder:       0.621301775147929\n",
      "accuracy WITH encoder:          0.6206443129520053\n",
      "f1 score WITHOUT encoder:       0.47855612616401005\n",
      "f1 score WITH encoder:          0.4758692703769939\n",
      "precision WITHOUT encoder:      0.5755637294098832\n",
      "precision WITH encoder:         0.38586110246029276\n",
      "recall WITHOUT encoder:         0.621301775147929\n",
      "recall WITH encoder:            0.6206443129520053\n",
      "roc auc score WITHOUT encoder:  0.5006779100529102\n",
      "roc auc score WITH encoder:     0.49947089947089945\n"
     ]
    }
   ],
   "source": [
    "#BORUTA\n",
    "normal_acc=[]\n",
    "encoder_acc=[]\n",
    "# load the model from file\n",
    "encoder = load_model('encoder_boruta.h5',compile=False)\n",
    "#1.0 prepare the data\n",
    "feature_selection= pd.read_excel('L2_comp.xlsx', sep=';',decimal='.')\n",
    "boruta_selected=feature_selection[feature_selection['BORUTA']>=600]\n",
    "feature_selected_boruta=boruta_selected['features']\n",
    "X=data[feature_selected_boruta]\n",
    "X=X.to_numpy()\n",
    "y=data[label].map({'Positive': 0, 'Negative':1})\n",
    "y=y.to_numpy()\n",
    "y_pred=y-y\n",
    "y_pred=y_pred.reshape(-1,1)\n",
    "y_pred_encode=y-y\n",
    "y_pred_encode=y_pred_encode.reshape(-1,1)\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    \n",
    "    # mi creo i punti di train e di test\n",
    "    X_train, X_test = X[train_index,:], X[test_index,:]\n",
    "    #creo le label del train e quelle del test\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    # scale data\n",
    "    t = MinMaxScaler()\n",
    "    t.fit(X_train)\n",
    "    X_train = t.transform(X_train)\n",
    "    X_test = t.transform(X_test)\n",
    "\n",
    "    # encode the train data\n",
    "    X_train_encode = encoder.predict(X_train)\n",
    "    # encode the test data\n",
    "    X_test_encode = encoder.predict(X_test)\n",
    "    \n",
    "    #1.1 model with X_train\n",
    "    # define the keras model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile the keras model\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit the keras model on the dataset\n",
    "    model.fit(X_train, y_train, epochs=150, batch_size=10,verbose=0)\n",
    "    # evaluate the keras model\n",
    "    #_, accuracy = model.evaluate(X_test, y_test)\n",
    "    #normal_acc.append(accuracy)\n",
    "    y_pred[test_index]=model.predict(X_test)\n",
    "    \n",
    "    #1.2 model with X_train_encode\n",
    "    # define the keras model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile the keras model\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit the keras model on the dataset\n",
    "    model.fit(X_train_encode, y_train, epochs=150, batch_size=10,verbose=0)\n",
    "    # evaluate the keras model\n",
    "    #_, accuracy_encode = model.evaluate(X_test_encode, y_test)\n",
    "    #encoder_acc.append(accuracy_encode)\n",
    "    y_pred_encode[test_index]=model.predict(X_test_encode)\n",
    "\n",
    "print(\"accuracy WITHOUT encoder:      \",accuracy_score(y,y_pred))\n",
    "print(\"accuracy WITH encoder:         \",accuracy_score(y,y_pred_encode))\n",
    "print(\"f1 score WITHOUT encoder:      \",f1_score(y, y_pred, average='weighted'))\n",
    "print(\"f1 score WITH encoder:         \",f1_score(y, y_pred_encode, average='weighted'))\n",
    "print(\"precision WITHOUT encoder:     \",precision_score(y, y_pred, average='weighted'))\n",
    "print(\"precision WITH encoder:        \",precision_score(y, y_pred_encode, average='weighted'))\n",
    "print(\"recall WITHOUT encoder:        \",recall_score(y, y_pred, average='weighted'))\n",
    "print(\"recall WITH encoder:           \",recall_score(y, y_pred_encode, average='weighted'))\n",
    "print(\"roc auc score WITHOUT encoder: \",roc_auc_score(y, y_pred))\n",
    "print(\"roc auc score WITH encoder:    \",roc_auc_score(y, y_pred_encode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy WITHOUT encoder:       0.6232741617357002\n",
      "accuracy WITH encoder:          0.6219592373438527\n",
      "f1 score WITHOUT encoder:       0.4806845268025458\n",
      "f1 score WITH encoder:          0.47768601467378075\n",
      "precision WITHOUT encoder:      0.7654769979184695\n",
      "precision WITH encoder:         0.7649680784802242\n",
      "recall WITHOUT encoder:         0.6232741617357002\n",
      "recall WITH encoder:            0.6219592373438527\n",
      "roc auc score WITHOUT encoder:  0.5026041666666666\n",
      "roc auc score WITH encoder:     0.5008680555555556\n"
     ]
    }
   ],
   "source": [
    "#MRMR\n",
    "normal_acc=[]\n",
    "encoder_acc=[]\n",
    "# load the model from file\n",
    "encoder = load_model('encoder_mrmr.h5',compile=False)\n",
    "#1.0 prepare the data\n",
    "feature_selection= pd.read_excel('L2_comp.xlsx', sep=';',decimal='.')\n",
    "boruta_selected=feature_selection[feature_selection['MRMR']>=600]\n",
    "feature_selected_boruta=boruta_selected['features']\n",
    "X=data[feature_selected_boruta]\n",
    "X=X.to_numpy()\n",
    "y=data[label].map({'Positive': 0, 'Negative':1})\n",
    "y=y.to_numpy()\n",
    "y_pred=y-y\n",
    "y_pred=y_pred.reshape(-1,1)\n",
    "y_pred_encode=y-y\n",
    "y_pred_encode=y_pred_encode.reshape(-1,1)\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    \n",
    "    # mi creo i punti di train e di test\n",
    "    X_train, X_test = X[train_index,:], X[test_index,:]\n",
    "    #creo le label del train e quelle del test\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    # scale data\n",
    "    t = MinMaxScaler()\n",
    "    t.fit(X_train)\n",
    "    X_train = t.transform(X_train)\n",
    "    X_test = t.transform(X_test)\n",
    "\n",
    "    # encode the train data\n",
    "    X_train_encode = encoder.predict(X_train)\n",
    "    # encode the test data\n",
    "    X_test_encode = encoder.predict(X_test)\n",
    "    \n",
    "    #1.1 model with X_train\n",
    "    # define the keras model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile the keras model\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit the keras model on the dataset\n",
    "    model.fit(X_train, y_train, epochs=150, batch_size=10,verbose=0)\n",
    "    # evaluate the keras model\n",
    "    #_, accuracy = model.evaluate(X_test, y_test)\n",
    "    #normal_acc.append(accuracy)\n",
    "    y_pred[test_index]=model.predict(X_test)\n",
    "        \n",
    "    #1.2 model with X_train_encode\n",
    "    # define the keras model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile the keras model\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit the keras model on the dataset\n",
    "    model.fit(X_train_encode, y_train, epochs=150, batch_size=10,verbose=0)\n",
    "    # evaluate the keras model\n",
    "    #_, accuracy_encode = model.evaluate(X_test_encode, y_test)\n",
    "    #encoder_acc.append(accuracy_encode)\n",
    "    y_pred_encode[test_index]=model.predict(X_test_encode)\n",
    "\n",
    "print(\"accuracy WITHOUT encoder:      \",accuracy_score(y,y_pred))\n",
    "print(\"accuracy WITH encoder:         \",accuracy_score(y,y_pred_encode))\n",
    "print(\"f1 score WITHOUT encoder:      \",f1_score(y, y_pred, average='weighted'))\n",
    "print(\"f1 score WITH encoder:         \",f1_score(y, y_pred_encode, average='weighted'))\n",
    "print(\"precision WITHOUT encoder:     \",precision_score(y, y_pred, average='weighted'))\n",
    "print(\"precision WITH encoder:        \",precision_score(y, y_pred_encode, average='weighted'))\n",
    "print(\"recall WITHOUT encoder:        \",recall_score(y, y_pred, average='weighted'))\n",
    "print(\"recall WITH encoder:           \",recall_score(y, y_pred_encode, average='weighted'))\n",
    "print(\"roc auc score WITHOUT encoder: \",roc_auc_score(y, y_pred))\n",
    "print(\"roc auc score WITH encoder:    \",roc_auc_score(y, y_pred_encode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy WITHOUT encoder:       0.6278763971071664\n",
      "accuracy WITH encoder:          0.6219592373438527\n",
      "f1 score WITHOUT encoder:       0.4965956531945022\n",
      "f1 score WITH encoder:          0.4788719073498496\n",
      "precision WITHOUT encoder:      0.6731133879189022\n",
      "precision WITH encoder:         0.6388349665941639\n",
      "recall WITHOUT encoder:         0.6278763971071664\n",
      "recall WITH encoder:            0.6219592373438527\n",
      "roc auc score WITHOUT encoder:  0.5103753306878307\n",
      "roc auc score WITH encoder:     0.5012070105820106\n"
     ]
    }
   ],
   "source": [
    "#UNION\n",
    "normal_acc=[]\n",
    "encoder_acc=[]\n",
    "# load the model from file\n",
    "encoder = load_model('encoder_union.h5',compile=False)\n",
    "#1.0 prepare the data\n",
    "feature_selection= pd.read_excel('L2_comp.xlsx', sep=';',decimal='.')\n",
    "boruta_selected=feature_selection[feature_selection['UNION']>=600]\n",
    "feature_selected_boruta=boruta_selected['features']\n",
    "X=data[feature_selected_boruta]\n",
    "X=X.to_numpy()\n",
    "y=data[label].map({'Positive': 0, 'Negative':1})\n",
    "y=y.to_numpy()\n",
    "y_pred=y-y\n",
    "y_pred=y_pred.reshape(-1,1)\n",
    "y_pred_encode=y-y\n",
    "y_pred_encode=y_pred_encode.reshape(-1,1)\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    \n",
    "    # mi creo i punti di train e di test\n",
    "    X_train, X_test = X[train_index,:], X[test_index,:]\n",
    "    #creo le label del train e quelle del test\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    # scale data\n",
    "    t = MinMaxScaler()\n",
    "    t.fit(X_train)\n",
    "    X_train = t.transform(X_train)\n",
    "    X_test = t.transform(X_test)\n",
    "\n",
    "    # encode the train data\n",
    "    X_train_encode = encoder.predict(X_train)\n",
    "    # encode the test data\n",
    "    X_test_encode = encoder.predict(X_test)\n",
    "    \n",
    "    #1.1 model with X_train\n",
    "    # define the keras model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile the keras model\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit the keras model on the dataset\n",
    "    model.fit(X_train, y_train, epochs=150, batch_size=10,verbose=0)\n",
    "    # evaluate the keras model\n",
    "    #_, accuracy = model.evaluate(X_test, y_test)\n",
    "    #normal_acc.append(accuracy)\n",
    "    y_pred[test_index]=model.predict(X_test)\n",
    "        \n",
    "    #1.2 model with X_train_encode\n",
    "    # define the keras model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile the keras model\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit the keras model on the dataset\n",
    "    model.fit(X_train_encode, y_train, epochs=150, batch_size=10,verbose=0)\n",
    "    # evaluate the keras model\n",
    "    #_, accuracy_encode = model.evaluate(X_test_encode, y_test)\n",
    "    #encoder_acc.append(accuracy_encode)\n",
    "    y_pred_encode[test_index]=model.predict(X_test_encode)\n",
    "\n",
    "print(\"accuracy WITHOUT encoder:      \",accuracy_score(y,y_pred))\n",
    "print(\"accuracy WITH encoder:         \",accuracy_score(y,y_pred_encode))\n",
    "print(\"f1 score WITHOUT encoder:      \",f1_score(y, y_pred, average='weighted'))\n",
    "print(\"f1 score WITH encoder:         \",f1_score(y, y_pred_encode, average='weighted'))\n",
    "print(\"precision WITHOUT encoder:     \",precision_score(y, y_pred, average='weighted'))\n",
    "print(\"precision WITH encoder:        \",precision_score(y, y_pred_encode, average='weighted'))\n",
    "print(\"recall WITHOUT encoder:        \",recall_score(y, y_pred, average='weighted'))\n",
    "print(\"recall WITH encoder:           \",recall_score(y, y_pred_encode, average='weighted'))\n",
    "print(\"roc auc score WITHOUT encoder: \",roc_auc_score(y, y_pred))\n",
    "print(\"roc auc score WITH encoder:    \",roc_auc_score(y, y_pred_encode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy WITHOUT encoder:       0.621301775147929\n",
      "accuracy WITH encoder:          0.621301775147929\n",
      "f1 score WITHOUT encoder:       0.4761801926316244\n",
      "f1 score WITH encoder:          0.4761801926316244\n",
      "precision WITHOUT encoder:      0.3860158958019677\n",
      "precision WITH encoder:         0.3860158958019677\n",
      "recall WITHOUT encoder:         0.621301775147929\n",
      "recall WITH encoder:            0.621301775147929\n",
      "roc auc score WITHOUT encoder:  0.5\n",
      "roc auc score WITH encoder:     0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marco\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#INTERSECT\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "normal_acc=[]\n",
    "encoder_acc=[]\n",
    "# load the model from file\n",
    "encoder = load_model('encoder_intersect.h5',compile=False)\n",
    "#1.0 prepare the data\n",
    "feature_selection= pd.read_excel('L2_comp.xlsx')\n",
    "boruta_selected=feature_selection[feature_selection['INTERSECT']>=600]\n",
    "feature_selected_boruta=boruta_selected['features']\n",
    "X=data[feature_selected_boruta]\n",
    "X=X.to_numpy()\n",
    "y=data[label].map({'Positive': 0, 'Negative':1})\n",
    "y=y.to_numpy()\n",
    "y_pred=y-y\n",
    "y_pred=y_pred.reshape(-1,1)\n",
    "y_pred_encode=y-y\n",
    "y_pred_encode=y_pred_encode.reshape(-1,1)\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    \n",
    "    # mi creo i punti di train e di test\n",
    "    X_train, X_test = X[train_index,:], X[test_index,:]\n",
    "    #creo le label del train e quelle del test\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    # scale data\n",
    "    t = MinMaxScaler()\n",
    "    t.fit(X_train)\n",
    "    X_train = t.transform(X_train)\n",
    "    X_test = t.transform(X_test)\n",
    "\n",
    "    # encode the train data\n",
    "    X_train_encode = encoder.predict(X_train)\n",
    "    # encode the test data\n",
    "    X_test_encode = encoder.predict(X_test)\n",
    "    \n",
    "    #1.1 model with X_train\n",
    "    # define the keras model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile the keras model\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit the keras model on the dataset\n",
    "    model.fit(X_train, y_train, epochs=150, batch_size=10,verbose=0)\n",
    "    # evaluate the keras model\n",
    "    #_, accuracy = model.evaluate(X_test, y_test)\n",
    "    #normal_acc.append(accuracy)\n",
    "    y_pred[test_index]=model.predict(X_test)\n",
    "\n",
    "    #1.2 model with X_train_encode\n",
    "    # define the keras model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile the keras model\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit the keras model on the dataset\n",
    "    model.fit(X_train_encode, y_train, epochs=150, batch_size=10,verbose=0)\n",
    "    # evaluate the keras model\n",
    "    #_, accuracy_encode = model.evaluate(X_test_encode, y_test)\n",
    "    #encoder_acc.append(accuracy_encode)\n",
    "    y_pred_encode[test_index]=model.predict(X_test_encode)\n",
    "\n",
    "print(\"accuracy WITHOUT encoder:      \",accuracy_score(y,y_pred))\n",
    "print(\"accuracy WITH encoder:         \",accuracy_score(y,y_pred_encode))\n",
    "print(\"f1 score WITHOUT encoder:      \",f1_score(y, y_pred, average='weighted'))\n",
    "print(\"f1 score WITH encoder:         \",f1_score(y, y_pred_encode, average='weighted'))\n",
    "print(\"precision WITHOUT encoder:     \",precision_score(y, y_pred, average='weighted'))\n",
    "print(\"precision WITH encoder:        \",precision_score(y, y_pred_encode, average='weighted'))\n",
    "print(\"recall WITHOUT encoder:        \",recall_score(y, y_pred, average='weighted'))\n",
    "print(\"recall WITH encoder:           \",recall_score(y, y_pred_encode, average='weighted'))\n",
    "print(\"roc auc score WITHOUT encoder: \",roc_auc_score(y, y_pred))\n",
    "print(\"roc auc score WITH encoder:    \",roc_auc_score(y, y_pred_encode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
