# MODELLI-DI-PREVISIONE-DEL-RISCHIO-DI-MORTALIT-PER-PAZIENTI-COVID
Il lavoro da me svolto durante il periodo tirocinio riguarda l’ambito dell’apprendimento automatico. Lo scopo è stato quello di sviluppare un metodo supervisionato per la predizione del rischio di mortalità per pazienti COVID-19, al fine di individuare per tempo pazienti positivi alla malattia e soprattutto capire quanto la malattia fosse grave per i singoli pazienti. Per lo sviluppo del progetto è stato utilizzato un dataset proveniente da due ospedali cinesi: l’Union Hospital (che ha fornito i dati di 1126 pazienti) e il Liyuan Hospitali (che ha fornito i dati di altri 295 pazienti). Il lavoro è iniziato con l’imputazione dei valori mancanti del dataset tramite l’algoritmo ‘MissForest’. Un valore mancante può avere diversi significati. È possibile che il campo non fosse applicabile, che l'evento non si sia verificato o che i dati non fossero disponibili. Potrebbe essere accaduto che la persona che ha immesso i dati non conoscesse il valore corretto o non abbia verificato l'effettiva compilazione di un campo[12] . Missforest è un algoritmo di imputazione basato sull'utilizzo di Random Forest. Inizialmente i valori mancanti del dataset sono stati sostituiti con la media delle osservazioni di quella variabile (per le variabili continue) o con la sua classe più frequente (per le variabili categoriche). Dopo di che, per ogni variabile (che all’interno dell’elaborato ho anche chiamato coi termini feature, attributo e caratteristica) avente valori mancanti, MissForest addestra una random forest sulla parte di dati non mancanti e prevede i mancanti della medesima variabile. Quando non sono più presenti dati mancanti per tutte le variabili, viene completata un'iterazione. Le imputazioni continuano per più iterazioni (vedremo più avanti il perché). Una volta ottenuto un dataset privo di valori mancanti, sono stati applicati e confrontati due algoritmi di feature selection: Boruta e MRMR. La “Feature selection” è il processo di riduzione del numero di variabili di input durante lo sviluppo di un modello predittivo. Gli algoritmi di feature selection possono essere divisi in “minimal-optimal” o “all-relevant”. Boruta è un algoritmo del tipo “all-relevant”, ovvero trova un sottoinsieme di caratteristiche dal dataset che, individualmente, sono rilevanti per una data classificazione. MRMR (chè è un algoritmo minimal optimal) invece cerca di identificare un insieme di caratteristiche che nella loro totalità e non nella singolarità abbiano il massimo potere predittivo possibile. Con Boruta, le feature non competono tra loro ma con una versione randomizzata di loro stesse (le shadow feature; anche questo argomento verrà trattato a dovere nei capitoli successivi). Quando l'importanza di una feature del dataset è superiore a quella della shadow feature più importante, abbiamo una "hit", ovvero la feature in questione viene scelta da Boruta. Con MRMR invece, viene utilizzata la regola di selezione “Maximum Relevance - Minimum Redundancy” ovvero si seleziona ad ogni iterazione la feature che ha la massima rilevanza rispetto alla variabile target e la minima ridondanza rispetto alle caratteristiche che sono state già selezionate nelle iterazioni precedenti. Oltre all’analisi di questi due algoritmi, sono stati anche analizzati i casi in cui venivano prese le feature selezionate dall’unione e intersezione dei due algoritmi sopra citati. Finita la fase di feature selection, è stato implementato un autoencoder, un tipo di rete neurale composta da due sub-model: un encoder e un decoder. Una volta che l’autoencoder è stato addestrato, la parte di decoder è stata scartata ed è stato utilizzato solo il modello fino al bottleneck (l’encoder). L'output dell’encoder è un vettore a lunghezza fissa che fornisce una rappresentazione compressa dei dati di input. L'encoder addestrato è stato poi utilizzato per comprimere i dati di input e addestrare un modello predittivo, in questo caso una semplice rete neurale. L’obiettivo è stato quello di addestrare una rete neurale con i dati compressi e una rete  4 neurale con i dati originali del dataset e vedere se si otteneva una sorta di miglioramento con i dati compressi provenienti dall’encoder. Le tecniche di feature selection e addestramento della rete neurale citata nel precedente capoverso sono state sperimentate applicando k-fold cross-validation. I risultati dei modelli predittivi sviluppati sono stati valutati tramite metriche quali F1-score, accuratezza, precisione, recall e ROC AUC. L’elaborato è organizzato in tre capitoli. Il primo capitolo contiene l’introduzione all’elaborato dove viene fatto un riassunto di come il COVID-19 abbia cambiato le nostre vite e di come esso abbia anche impattato il mondo scientifico, soprattutto quello medico e informatico. Il secondo capitolo è inerente al background teorico e spiega la teoria che sta alla base di ciò che è stato poi messo in pratica. L’ultimo capitolo è dedicato alla descrizione di come sono state implementati i metodi descritti nel capitolo precedente e di quali risultati si sono ottenuti, anche attraverso l’utilizzo di tabelle e figure.

# CODE EXPLANATION
Nel notebook "Miss_Data_imputation" viene effetuata l'imputazione di valori mancanti tramite Miass forest. Nel notebook ALTAIR_VARIANCES vengon visualizzati i risultati. Nel notebook MRMR&BORUTA è stata applicata feature selection sulle variabili del dataset. La feature selection consiste nell'applicare la selezione tramite Boruta, MRMR, l'intersezione delle due e l'unione delle due. Come ultimo passo nel notebook "Autoencoider" è stato creato un autoencoder per ogni dataset generato dalle varie feature selection. I dati compressi generati dalla parte di encoder dell'autoencoder sono stati poi usati per allenare una Neural Network e i risultati sono stati poi conforntati con quelli provenienti dalle stessa NN MA con i dati originali (quindi non compressi). 

